{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hibah45/ResearchWork/blob/main/RFpruningMobilePrice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "GZwIlEBn4E3o",
        "outputId": "1e6f9824-a2e8-4421-aee3-6a362ad59151"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
              "0            842     0          2.2         0   1       0           7    0.6   \n",
              "1           1021     1          0.5         1   0       1          53    0.7   \n",
              "2            563     1          0.5         1   2       1          41    0.9   \n",
              "3            615     1          2.5         0   0       0          10    0.8   \n",
              "4           1821     1          1.2         0  13       1          44    0.6   \n",
              "\n",
              "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
              "0        188        2  ...         20       756  2549     9     7         19   \n",
              "1        136        3  ...        905      1988  2631    17     3          7   \n",
              "2        145        5  ...       1263      1716  2603    11     2          9   \n",
              "3        131        6  ...       1216      1786  2769    16     8         11   \n",
              "4        141        2  ...       1208      1212  1411     8     2         15   \n",
              "\n",
              "   three_g  touch_screen  wifi  price_range  \n",
              "0        0             0     1            1  \n",
              "1        1             1     0            2  \n",
              "2        1             1     0            2  \n",
              "3        1             0     0            2  \n",
              "4        1             1     0            1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-898df83a-20cb-4da0-b8ec-9732d40c49b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>...</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842</td>\n",
              "      <td>0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>188</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>756</td>\n",
              "      <td>2549</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0.7</td>\n",
              "      <td>136</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>905</td>\n",
              "      <td>1988</td>\n",
              "      <td>2631</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>563</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0.9</td>\n",
              "      <td>145</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>1263</td>\n",
              "      <td>1716</td>\n",
              "      <td>2603</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>615</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>131</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>1216</td>\n",
              "      <td>1786</td>\n",
              "      <td>2769</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1821</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>0.6</td>\n",
              "      <td>141</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>1208</td>\n",
              "      <td>1212</td>\n",
              "      <td>1411</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-898df83a-20cb-4da0-b8ec-9732d40c49b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-898df83a-20cb-4da0-b8ec-9732d40c49b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-898df83a-20cb-4da0-b8ec-9732d40c49b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn import cluster, datasets, mixture\n",
        "from sklearn import metrics\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fileURL = \"https://github.com/Hibah45/ResearchWork/blob/main/MobilePricetrain.csv?raw=True\"\n",
        "\n",
        "data = pd.read_csv(fileURL)\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSmc2uuw4tOW",
        "outputId": "889d060f-c8cf-4c4f-f4ff-0d1d0d167ba1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['price_range']\n",
        "# Create X\n",
        "X = data.iloc[:,:-1]\n"
      ],
      "metadata": {
        "id": "vgr-ynUCUUyA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xIW45Zcf45c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bed5ee4-99d9-436a-dfa9-f33331b52510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8766666666666667\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.91       156\n",
            "           1       0.81      0.87      0.84       159\n",
            "           2       0.83      0.83      0.83       143\n",
            "           3       0.94      0.92      0.93       142\n",
            "\n",
            "    accuracy                           0.88       600\n",
            "   macro avg       0.88      0.88      0.88       600\n",
            "weighted avg       0.88      0.88      0.88       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
        "\n",
        "# X, y = make_classification(n_samples=10, n_features=4,\n",
        "#                            n_informative=2, n_redundant=0, \n",
        "#                            random_state=0, shuffle=False)\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "#clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "prec_rec = classification_report(y_pred, y_test)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(prec_rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU2-2UBn6ZOt",
        "outputId": "a0e745bc-6c60-44e5-d0ff-c5b9189427f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier(max_features='auto', random_state=1383306309)\n"
          ]
        }
      ],
      "source": [
        "ind_tree = (clf.estimators_[4])\n",
        "print(ind_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FIaBQoGR7gdl"
      },
      "outputs": [],
      "source": [
        "class PrunedRandomForest:\n",
        "\n",
        "\n",
        "    def __init__(self, n_clusters = 10 , n_estimators = 300, cv = 5):\n",
        "        \"\"\" this is the unpruned random forest \"\"\"\n",
        "        self.rf = RandomForestClassifier(n_estimators = n_estimators)\n",
        "\n",
        "        \"\"\" this is the final pruned random forest \"\"\"\n",
        "        self.prf = None \n",
        "        self.prf1 = None \n",
        "\n",
        "        \n",
        "        \"\"\"this is a list of decision tree object present in original unpruned random forest\"\"\"\n",
        "        self.decision_trees = None \n",
        "        \n",
        "        \"\"\"number of clusters for pruning\"\"\"\n",
        "        self.n_clusters = n_clusters \n",
        "        \n",
        "        \n",
        "\n",
        "        \"\"\" \n",
        "            this contains dictionary of lists where each element of dictionary represetns a\n",
        "            pair (cluster_idx, tree_idx_list)\n",
        "\n",
        "            where tree_idx_list is list of decision tree indices and cluster_idx is index of cluster \n",
        "            e.g.\n",
        "            \n",
        "            {\n",
        "                0 : [2, 0]\n",
        "                1 : [1, 3]\n",
        "            }\n",
        "            it means decision tree at 2nd index and 0th index \n",
        "            are in same cluster similarly 1st and 3rd in second cluster\n",
        "\n",
        "        \"\"\" \n",
        "        self.clusters = {}\n",
        "        \n",
        "        self.cv = cv\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "            Information about all trees in the random forest present in this \n",
        "            form\n",
        "            {\n",
        "                idx : { \n",
        "                    accuracy : 89.34\n",
        "                    cluster : 2\n",
        "                }\n",
        "\n",
        "                idx1 : {\n",
        "\n",
        "                }\n",
        "            }\n",
        "        \"\"\"\n",
        "        self.info = {}\n",
        "        #self.maxs_accuracy = {}\n",
        "        self.fimps = None\n",
        "\n",
        "    def prune(self):\n",
        "        pass\n",
        "\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.rf.fit(X,y)\n",
        "        self.decision_trees = self.rf.estimators_\n",
        "        self.create_feature_imp_clusters()\n",
        "        self.create_feature_imp_clusters1()\n",
        "        self.create_fimp_agglomerative()\n",
        "        self.create_fimp_gaussian()\n",
        "        self.create_fimp_spectral_clustering()\n",
        "        #self.plot_clusters(X,y)\n",
        "        #self.all_algorithms()\n",
        "\n",
        "        self.fill_info(X, y)\n",
        "        #self.max_accuracy(X,y)\n",
        "        self.prune()\n",
        "\n",
        "    def fill_info(self, X, y):\n",
        "        for idx, tree in enumerate(self.decision_trees):\n",
        "            self.info[idx] = self.fill_for_tree(tree, X, y)\n",
        "\n",
        "        for cluster_idx in self.clusters:\n",
        "            for tree_idx in self.clusters[cluster_idx]:\n",
        "                self.info[tree_idx][\"cluster_idx\"] = cluster_idx \n",
        "       \n",
        "\n",
        "    \"\"\"\n",
        "        {\n",
        "            \"accuracy\" : 98.45,\n",
        "            \n",
        "        } \n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def fill_for_tree(self, tree, X, y):\n",
        "        info = {}\n",
        "        mean_score = cross_val_score(tree, X, y, cv=self.cv).mean()\n",
        "        info[\"accuracy\"] = (mean_score)\n",
        "        return info\n",
        "\n",
        "    def predict(self, X):\n",
        "        if(self.prf is None):\n",
        "            return None\n",
        "        \n",
        "        return self.prf.predict(X)\n",
        "\n",
        "    \n",
        "    def get_decision_trees(self):\n",
        "        return self.decision_trees\n",
        "\n",
        "    def get_feature_imps_from_rf(self):\n",
        "        feature_imp_list = []\n",
        "        dts = self.get_decision_trees()\n",
        "        for tree in dts:\n",
        "            feature_imp_list.append(tree.feature_importances_)\n",
        "        return feature_imp_list\n",
        "\n",
        "    def create_feature_imp_clusters(self):\n",
        "        fimps = self.get_feature_imps_from_rf()\n",
        "        #print(fimps)\n",
        "        #print(\"KMEANS\")\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=0).fit(fimps)\n",
        "\n",
        "        print(\" fimps len = \" + str(len(fimps)))\n",
        "        labels = kmeans.labels_\n",
        "        score = silhouette_score(fimps, labels, metric='euclidean')\n",
        "        print('Silhouetter Score: %.3f' % score)\n",
        "        #print(labels)\n",
        "        print(\" kmeans.labels_ len = \" + str(len(kmeans.labels_)))\n",
        "        for (tree_idx, cluster_idx) in enumerate(kmeans.labels_):\n",
        "            if cluster_idx in self.clusters:\n",
        "                self.clusters[cluster_idx].append(tree_idx)\n",
        "            else:\n",
        "                self.clusters[cluster_idx] = [tree_idx]\n",
        "        \n",
        "    def create_feature_imp_clusters1(self):\n",
        "        fimps = self.get_feature_imps_from_rf()\n",
        "        #print(\"DBSCAN-\")\n",
        "        dbscan = DBSCAN().fit(fimps)\n",
        "\n",
        "        print(\" fimps len = \" + str(len(fimps)))\n",
        "        labels = dbscan.labels_\n",
        "        #print(labels)\n",
        "        print(\" dbscan.labels_ len = \" + str(len(labels)))\n",
        "        \n",
        "\n",
        "    def create_fimp_agglomerative(self):\n",
        "        fimps = self.get_feature_imps_from_rf()\n",
        "        #print(\"AGGLOMERATIVE CLUSTERING-\")\n",
        "        groups = AgglomerativeClustering(n_clusters=self.n_clusters).fit(fimps)\n",
        "        #print(groups.labels_)\n",
        "\n",
        "    def create_fimp_gaussian(self):\n",
        "      fimps = self.get_feature_imps_from_rf()\n",
        "      #print(\"GAUSSIAN CLUSTERING-\")\n",
        "      gmm =GaussianMixture(n_components = 5)\n",
        "      gmm.fit(fimps)\n",
        "      labelsgmm = gmm.predict(fimps)\n",
        "      #print(labelsgmm)\n",
        "      \n",
        "    def create_fimp_spectral_clustering(self):\n",
        "      fimps = self.get_feature_imps_from_rf()\n",
        "      models = SpectralClustering(n_clusters=6, random_state=25, n_neighbors=8, affinity='nearest_neighbors')\n",
        "      models.fit(fimps)\n",
        "      labelsx = models.fit_predict(fimps)\n",
        "      #print(labelsx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzfqyHYkr1Jo",
        "outputId": "c992e380-73e0-43bf-f7b4-bb5903beb0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " fimps len = 100\n",
            "Silhouetter Score: 0.203\n",
            " kmeans.labels_ len = 100\n",
            " fimps len = 100\n",
            " dbscan.labels_ len = 100\n",
            "KMEANS-\n",
            "3 ==>  [0, 4, 8, 19, 21, 22, 30, 33, 35, 37, 39, 41, 43, 46, 50, 52, 55, 59, 64, 75, 79, 80, 83, 88, 89, 92]\n",
            "2 ==>  [1, 3, 6, 10, 18, 49, 54, 63, 65, 67, 74, 95]\n",
            "0 ==>  [2, 11, 15, 16, 17, 23, 27, 28, 32, 34, 36, 38, 42, 48, 53, 57, 58, 61, 76, 86, 87]\n",
            "4 ==>  [5, 12, 14, 24, 25, 26, 29, 60, 66, 73, 90, 91, 94, 96]\n",
            "1 ==>  [7, 9, 13, 20, 44, 45, 56, 77, 84, 85, 93, 97]\n",
            "5 ==>  [31, 40, 47, 51, 62, 68, 69, 70, 71, 72, 78, 81, 82, 98, 99]\n",
            " fimps len = 100\n",
            "Silhouetter Score: 0.204\n",
            " kmeans.labels_ len = 100\n",
            " fimps len = 100\n",
            " dbscan.labels_ len = 100\n",
            "DBSCAN-\n",
            "3 ==>  [0, 10, 11, 29, 38, 41, 43, 49, 52, 53, 64, 70, 72, 78, 81, 98]\n",
            "1 ==>  [1, 16, 20, 22, 24, 25, 26, 28, 30, 32, 34, 35, 36, 37, 39, 40, 42, 50, 51, 56, 62, 71, 74, 75, 80, 86, 87, 91, 96]\n",
            "5 ==>  [2, 3, 8, 19, 21, 33, 46, 57, 59, 61, 63, 66, 68, 69, 77, 82, 84, 85, 89, 93, 99]\n",
            "2 ==>  [4, 17, 27, 44, 45, 48, 54, 55, 60, 67, 76, 79, 83, 90]\n",
            "0 ==>  [5, 6, 7, 12, 13, 14, 15, 18, 23, 47, 65, 92, 94, 95, 97]\n",
            "4 ==>  [9, 31, 58, 73, 88]\n",
            " fimps len = 100\n",
            "Silhouetter Score: 0.294\n",
            " kmeans.labels_ len = 100\n",
            " fimps len = 100\n",
            " dbscan.labels_ len = 100\n",
            "AGGLO\n",
            "0 ==>  [0, 3, 19, 25, 40, 47, 49, 52, 53, 57, 76, 78, 79, 85, 89, 91, 97]\n",
            "3 ==>  [1, 8, 14, 21, 22, 32, 35, 39, 42, 51, 59, 67, 68, 72, 74, 75, 94, 96]\n",
            "1 ==>  [2, 4, 5, 16, 18, 23, 26, 28, 29, 30, 33, 37, 38, 45, 46, 50, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 69, 70, 71, 81, 83, 84, 86, 90, 98, 99]\n",
            "2 ==>  [6, 7, 9, 10, 11, 12, 13, 15, 17, 20, 24, 27, 31, 34, 36, 41, 43, 44, 48, 66, 73, 77, 80, 82, 87, 88, 92, 93, 95]\n",
            " fimps len = 100\n",
            "Silhouetter Score: 0.210\n",
            " kmeans.labels_ len = 100\n",
            " fimps len = 100\n",
            " dbscan.labels_ len = 100\n",
            "Gaussian\n",
            "4 ==>  [0, 8, 9, 14, 16, 18, 23, 28, 29, 31, 42, 47, 48, 58, 59, 64, 75, 80, 81, 86, 89, 90, 93, 96]\n",
            "1 ==>  [1, 10, 25, 34, 38, 43, 44, 54, 57, 65, 66, 77, 82, 85]\n",
            "3 ==>  [2, 6, 19, 20, 21, 27, 33, 35, 45, 46, 50, 53, 67, 70, 71, 79, 83, 84, 94, 97]\n",
            "0 ==>  [3, 4, 7, 26, 30, 32, 37, 39, 40, 52, 55, 56, 60, 61, 62, 69, 72, 74, 76, 78, 92, 95, 98]\n",
            "2 ==>  [5, 11, 12, 13, 15, 17, 22, 24, 36, 41, 49, 51, 63, 68, 73, 87, 88, 91, 99]\n",
            " fimps len = 100\n",
            "Silhouetter Score: 0.219\n",
            " kmeans.labels_ len = 100\n",
            " fimps len = 100\n",
            " dbscan.labels_ len = 100\n",
            "spectral clustering\n",
            "4 ==>  [0, 7, 9, 14, 27, 43, 45, 58, 61, 64, 66, 68, 77, 79, 80, 84, 86, 89, 90]\n",
            "1 ==>  [1, 5, 8, 11, 17, 18, 19, 20, 31, 32, 36, 38, 39, 44, 48, 54, 56, 70, 72, 73, 81, 87, 94, 95, 97]\n",
            "2 ==>  [2, 3, 4, 6, 12, 13, 15, 22, 24, 25, 34, 40, 46, 52, 59, 65, 67, 69, 74, 76, 99]\n",
            "5 ==>  [10, 28, 33, 37, 42, 53, 55, 82, 92, 98]\n",
            "0 ==>  [16, 21, 23, 26, 29, 30, 35, 41, 47, 50, 51, 57, 60, 62, 63, 71, 75, 78, 83, 85, 88, 91, 93]\n",
            "3 ==>  [49, 96]\n"
          ]
        }
      ],
      "source": [
        "prf = PrunedRandomForest(10, 300)\n",
        "prf.fit(X, y)\n",
        "print('KMEANS-')\n",
        "for cluster_idx in prf.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf.clusters[cluster_idx])\n",
        "\n",
        "prf1 = PrunedRandomForest()\n",
        "prf1.fit(X, y)\n",
        "print('DBSCAN-')\n",
        "for cluster_idx in prf1.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf1.clusters[cluster_idx])\n",
        "\n",
        "prf2 = PrunedRandomForest()\n",
        "prf2.fit(X, y)\n",
        "print('AGGLO')\n",
        "for cluster_idx in prf2.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf2.clusters[cluster_idx])\n",
        "\n",
        "prf3 = PrunedRandomForest()\n",
        "prf3.fit(X,y)\n",
        "print('Gaussian')\n",
        "for cluster_idx in prf3.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf3.clusters[cluster_idx])\n",
        "\n",
        "prf4 = PrunedRandomForest()\n",
        "prf4.fit(X,y)\n",
        "print('spectral clustering')\n",
        "for cluster_idx in prf4.clusters:\n",
        "          print(str(cluster_idx) + \" ==> \", prf4.clusters[cluster_idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lYcN1727hdJv"
      },
      "outputs": [],
      "source": [
        "  # def plot_clusters(model, X):\n",
        "  #     pred = model.fit(X)\n",
        "  #     clusters = unique(pred)\n",
        "  #     for cluster in clusters:\n",
        "  #       row_idx = where(pred == cluster)\n",
        "  #       # create scatter of these samples\n",
        "  #       col0 = getColumn(X, row_idx, 0)\n",
        "  #       col1 = getColumn(X, row_idx, 1)\n",
        "  #       pyplot.scatter(col0, col1)\n",
        "  #   # show the plot\n",
        "  #   pyplot.show()\n",
        "\n",
        "  #   def all_algorithms(self):\n",
        "  #       fimps = self.get_feature_imps_from_rf()\n",
        "  #       print(\"KMEANS\")\n",
        "  #       kmeans = self.plot_clusters(KMeans(n_clusters=self.n_clusters, random_state=0), fimps)\n",
        "  #       print(\"DBSCAN-\")\n",
        "  #       dbscan = self.plot_clusters(DBSCAN(), fimps)\n",
        "  #       print(\"AGGLOMERATIVE CLUSTERING-\")\n",
        "  #       groups = self.plot_clusters(AgglomerativeClustering(n_clusters=self.n_clusters), fimps)\n",
        "  #       print(\" fimps len = \" + str(len(fimps)))\n",
        "  #       #print(labels)\n",
        "  #       print(\" kmeans.labels_ len = \" + str(len(kmeans.labels_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "PNOSc02PVaCY",
        "outputId": "64ee069d-2150-4ef0-ccb1-7af98f245c08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgglomerativeClustering(n_clusters=4)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.title(\"Dendograms\")\n",
        "dend = shc.dendrogram(shc.linkage(X, method='ward'))\n",
        "groups = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage=\"ward\")\n",
        "groups.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prf.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drhPY0GiOF_q",
        "outputId": "0376c1e5-e7dd-44da-ef47-6d597aef4b30"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'accuracy': 0.6775, 'cluster_idx': 3},\n",
              " 1: {'accuracy': 0.7144999999999999, 'cluster_idx': 2},\n",
              " 2: {'accuracy': 0.6585000000000001, 'cluster_idx': 0},\n",
              " 3: {'accuracy': 0.6575, 'cluster_idx': 2},\n",
              " 4: {'accuracy': 0.6475000000000001, 'cluster_idx': 3},\n",
              " 5: {'accuracy': 0.639, 'cluster_idx': 4},\n",
              " 6: {'accuracy': 0.65, 'cluster_idx': 2},\n",
              " 7: {'accuracy': 0.5645, 'cluster_idx': 1},\n",
              " 8: {'accuracy': 0.6525000000000001, 'cluster_idx': 3},\n",
              " 9: {'accuracy': 0.5735, 'cluster_idx': 1},\n",
              " 10: {'accuracy': 0.739, 'cluster_idx': 2},\n",
              " 11: {'accuracy': 0.7030000000000001, 'cluster_idx': 0},\n",
              " 12: {'accuracy': 0.6100000000000001, 'cluster_idx': 4},\n",
              " 13: {'accuracy': 0.5705, 'cluster_idx': 1},\n",
              " 14: {'accuracy': 0.6565, 'cluster_idx': 4},\n",
              " 15: {'accuracy': 0.7024999999999999, 'cluster_idx': 0},\n",
              " 16: {'accuracy': 0.6105, 'cluster_idx': 0},\n",
              " 17: {'accuracy': 0.6724999999999999, 'cluster_idx': 0},\n",
              " 18: {'accuracy': 0.607, 'cluster_idx': 2},\n",
              " 19: {'accuracy': 0.62, 'cluster_idx': 3},\n",
              " 20: {'accuracy': 0.5914999999999999, 'cluster_idx': 1},\n",
              " 21: {'accuracy': 0.7030000000000001, 'cluster_idx': 3},\n",
              " 22: {'accuracy': 0.6460000000000001, 'cluster_idx': 3},\n",
              " 23: {'accuracy': 0.6455, 'cluster_idx': 0},\n",
              " 24: {'accuracy': 0.6595, 'cluster_idx': 4},\n",
              " 25: {'accuracy': 0.611, 'cluster_idx': 4},\n",
              " 26: {'accuracy': 0.626, 'cluster_idx': 4},\n",
              " 27: {'accuracy': 0.7464999999999999, 'cluster_idx': 0},\n",
              " 28: {'accuracy': 0.65, 'cluster_idx': 0},\n",
              " 29: {'accuracy': 0.6035, 'cluster_idx': 4},\n",
              " 30: {'accuracy': 0.634, 'cluster_idx': 3},\n",
              " 31: {'accuracy': 0.5915, 'cluster_idx': 5},\n",
              " 32: {'accuracy': 0.571, 'cluster_idx': 0},\n",
              " 33: {'accuracy': 0.652, 'cluster_idx': 3},\n",
              " 34: {'accuracy': 0.639, 'cluster_idx': 0},\n",
              " 35: {'accuracy': 0.6815, 'cluster_idx': 3},\n",
              " 36: {'accuracy': 0.5509999999999999, 'cluster_idx': 0},\n",
              " 37: {'accuracy': 0.6875, 'cluster_idx': 3},\n",
              " 38: {'accuracy': 0.6359999999999999, 'cluster_idx': 0},\n",
              " 39: {'accuracy': 0.71, 'cluster_idx': 3},\n",
              " 40: {'accuracy': 0.5825, 'cluster_idx': 5},\n",
              " 41: {'accuracy': 0.7255, 'cluster_idx': 3},\n",
              " 42: {'accuracy': 0.6615, 'cluster_idx': 0},\n",
              " 43: {'accuracy': 0.6094999999999999, 'cluster_idx': 3},\n",
              " 44: {'accuracy': 0.5765, 'cluster_idx': 1},\n",
              " 45: {'accuracy': 0.5895, 'cluster_idx': 1},\n",
              " 46: {'accuracy': 0.6599999999999999, 'cluster_idx': 3},\n",
              " 47: {'accuracy': 0.662, 'cluster_idx': 5},\n",
              " 48: {'accuracy': 0.5650000000000001, 'cluster_idx': 0},\n",
              " 49: {'accuracy': 0.7020000000000001, 'cluster_idx': 2},\n",
              " 50: {'accuracy': 0.712, 'cluster_idx': 3},\n",
              " 51: {'accuracy': 0.6145, 'cluster_idx': 5},\n",
              " 52: {'accuracy': 0.5465, 'cluster_idx': 3},\n",
              " 53: {'accuracy': 0.5529999999999999, 'cluster_idx': 0},\n",
              " 54: {'accuracy': 0.6865, 'cluster_idx': 2},\n",
              " 55: {'accuracy': 0.611, 'cluster_idx': 3},\n",
              " 56: {'accuracy': 0.5650000000000001, 'cluster_idx': 1},\n",
              " 57: {'accuracy': 0.6045, 'cluster_idx': 0},\n",
              " 58: {'accuracy': 0.658, 'cluster_idx': 0},\n",
              " 59: {'accuracy': 0.7234999999999999, 'cluster_idx': 3},\n",
              " 60: {'accuracy': 0.615, 'cluster_idx': 4},\n",
              " 61: {'accuracy': 0.5755, 'cluster_idx': 0},\n",
              " 62: {'accuracy': 0.6174999999999999, 'cluster_idx': 5},\n",
              " 63: {'accuracy': 0.6839999999999999, 'cluster_idx': 2},\n",
              " 64: {'accuracy': 0.727, 'cluster_idx': 3},\n",
              " 65: {'accuracy': 0.7035, 'cluster_idx': 2},\n",
              " 66: {'accuracy': 0.6235, 'cluster_idx': 4},\n",
              " 67: {'accuracy': 0.6975, 'cluster_idx': 2},\n",
              " 68: {'accuracy': 0.5265000000000001, 'cluster_idx': 5},\n",
              " 69: {'accuracy': 0.5925, 'cluster_idx': 5},\n",
              " 70: {'accuracy': 0.55, 'cluster_idx': 5},\n",
              " 71: {'accuracy': 0.5855, 'cluster_idx': 5},\n",
              " 72: {'accuracy': 0.5875, 'cluster_idx': 5},\n",
              " 73: {'accuracy': 0.604, 'cluster_idx': 4},\n",
              " 74: {'accuracy': 0.6615, 'cluster_idx': 2},\n",
              " 75: {'accuracy': 0.7365, 'cluster_idx': 3},\n",
              " 76: {'accuracy': 0.534, 'cluster_idx': 0},\n",
              " 77: {'accuracy': 0.5574999999999999, 'cluster_idx': 1},\n",
              " 78: {'accuracy': 0.546, 'cluster_idx': 5},\n",
              " 79: {'accuracy': 0.6875, 'cluster_idx': 3},\n",
              " 80: {'accuracy': 0.6555, 'cluster_idx': 3},\n",
              " 81: {'accuracy': 0.623, 'cluster_idx': 5},\n",
              " 82: {'accuracy': 0.5469999999999999, 'cluster_idx': 5},\n",
              " 83: {'accuracy': 0.6365000000000001, 'cluster_idx': 3},\n",
              " 84: {'accuracy': 0.591, 'cluster_idx': 1},\n",
              " 85: {'accuracy': 0.594, 'cluster_idx': 1},\n",
              " 86: {'accuracy': 0.6775, 'cluster_idx': 0},\n",
              " 87: {'accuracy': 0.7055, 'cluster_idx': 0},\n",
              " 88: {'accuracy': 0.6285000000000001, 'cluster_idx': 3},\n",
              " 89: {'accuracy': 0.6265, 'cluster_idx': 3},\n",
              " 90: {'accuracy': 0.5665, 'cluster_idx': 4},\n",
              " 91: {'accuracy': 0.6080000000000001, 'cluster_idx': 4},\n",
              " 92: {'accuracy': 0.5970000000000001, 'cluster_idx': 3},\n",
              " 93: {'accuracy': 0.568, 'cluster_idx': 1},\n",
              " 94: {'accuracy': 0.6275, 'cluster_idx': 4},\n",
              " 95: {'accuracy': 0.6455, 'cluster_idx': 2},\n",
              " 96: {'accuracy': 0.646, 'cluster_idx': 4},\n",
              " 97: {'accuracy': 0.5525, 'cluster_idx': 1},\n",
              " 98: {'accuracy': 0.5665, 'cluster_idx': 5},\n",
              " 99: {'accuracy': 0.5599999999999999, 'cluster_idx': 5}}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tXGhTURny7i_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac8b6b3f-c9ec-4dd1-b9b4-4e052b5286f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7464999999999999 0\n",
            "List of clusters with maximum accuracy is:\n",
            "\n",
            "Cluster index,Maximum accuracy,decision tree\n",
            " [[0, 0.7464999999999999, 27], [2, 0.739, 10]]\n"
          ]
        }
      ],
      "source": [
        "max_acc = -1\n",
        "max_acc_in_cluster = -1\n",
        "idx = \"\"\n",
        "lists = []\n",
        "list1 = []\n",
        "res = set()\n",
        "dicts = prf.info\n",
        "for k, subdict in dicts.items():\n",
        "      res.add(subdict['cluster_idx'])\n",
        "      if subdict['accuracy'] >= max_acc:\n",
        "        max_acc = subdict['accuracy']\n",
        "        idx = subdict['cluster_idx']\n",
        "        lists.append([max_acc,idx, k])\n",
        "        for i in range(len(res)):\n",
        "          if i == idx:\n",
        "            list1.append([i,max_acc,k])\n",
        "\n",
        "print(max_acc, idx)\n",
        "result = set([c for a, c, t in lists])\n",
        "result\n",
        "print(\"List of clusters with maximum accuracy is:\\n\")\n",
        "print(\"Cluster index,Maximum accuracy,decision tree\\n\",sorted(list1))\n",
        "\n",
        "#for each cluster get max acc nd tree to be selected as representsative\n",
        "#once all the cluster representatives are found ..remove all others ..prune function\n",
        "# calculated overall performance of random forest again-challenging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Highest acuracy selection-Cluster Representative\n",
        "def getMaxAccuracyCluster(dicts):\n",
        "    clusterObj = {}\n",
        "    for key, value in dicts.items():\n",
        "      if(clusterObj.get(str(value[\"cluster_idx\"])) != None):\n",
        "        clusterObj[str(value[\"cluster_idx\"])].append({\"index\" : key, \"accuracy\" : value['accuracy']})\n",
        "      else:\n",
        "        clusterObj[str(value[\"cluster_idx\"])] = []\n",
        "        clusterObj[str(value[\"cluster_idx\"])].append({\"index\" : key, \"accuracy\" : value['accuracy']})\n",
        "    #Restructured the object so the key for dictionary is cluster_idx\n",
        "    #Now you can access all the accuracies of cluster as below\n",
        "    #print(clusterObj[\"2\"])\n",
        "    clusterMaxAccuracyObj = {}\n",
        "    for clusterIndex in clusterObj.keys():\n",
        "      max_acc = -1;\n",
        "      for obj in clusterObj[clusterIndex]:\n",
        "        if obj['accuracy'] == max_acc:\n",
        "          clusterMaxAccuracyObj[str(clusterIndex)].append(obj['index'])\n",
        "        if obj['accuracy'] > max_acc:\n",
        "          max_acc = obj['accuracy']\n",
        "          clusterMaxAccuracyObj[str(clusterIndex)] = []\n",
        "          clusterMaxAccuracyObj[str(clusterIndex)].append(obj['index'])\n",
        "    print(clusterMaxAccuracyObj)\n",
        "    dict1 = {}\n",
        "    print(\"Selecting first maximum accuracy of a decision tree in each cluster:\")\n",
        "    for key,val in clusterMaxAccuracyObj.items():\n",
        "      output = {key : val[0]}\n",
        "      print(output)\n",
        "    return clusterMaxAccuracyObj"
      ],
      "metadata": {
        "id": "WW3VvbO-6Yah"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getMaxAccuracyCluster(prf.info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ__aUK-fUXj",
        "outputId": "7e0e0212-a747-4e26-85e3-338d2082ea5a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'3': [75], '2': [10], '0': [27], '4': [24], '1': [85], '5': [47]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'3': 75}\n",
            "{'2': 10}\n",
            "{'0': 27}\n",
            "{'4': 24}\n",
            "{'1': 85}\n",
            "{'5': 47}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': [27], '1': [85], '2': [10], '3': [75], '4': [24], '5': [47]}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prf.decision_trees[0].predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnvPjJ_fUmQt",
        "outputId": "2eaa42c3-74f9-4e1b-d321-7d36e732cfe0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 2., ..., 3., 0., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTreeList(X, dicts):\n",
        "    treeIdxs = []\n",
        "    for trees in dicts.values():\n",
        "        treeIdxs.append(trees[0])\n",
        "    return treeIdxs\n",
        "\n",
        "stored_ypred = []\n",
        "def predict(X, treeList, prf):\n",
        "    ypred = []\n",
        "    for treeIdx in treeList:\n",
        "        print(prf.decision_trees[treeIdx].predict(X))\n",
        "        ypred.append(prf.decision_trees[treeIdx].predict(X))\n",
        "    stored_ypred.append(ypred)\n",
        "    print(type(ypred))\n",
        "    return getMajorityLabels(ypred)\n",
        "\n",
        "def getMajorityLabels(pred):\n",
        "    predNp = np.array(pred)\n",
        "    rows,cols = predNp.shape\n",
        "    res = []\n",
        "    for colIdx in range(cols):\n",
        "        col = list(predNp[:, colIdx])\n",
        "        res.append(max(set(col), key = col.count))\n",
        "    return res\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dnbQIEqiEq29"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "  \n",
        "print(\"testing target data:\",y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcSWuOugEsLR",
        "outputId": "ed55bee4-f6ec-4467-8f90-7bddad123c97"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'3': [75], '2': [10], '0': [27], '4': [24], '1': [85], '5': [47]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'3': 75}\n",
            "{'2': 10}\n",
            "{'0': 27}\n",
            "{'4': 24}\n",
            "{'1': 85}\n",
            "{'5': 47}\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 0. 1. 0. 2. 0. 0. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 0. 0. 2. 2. 1. 0. 0. 1. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 1. 0. 1. 2. 2. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 2. 3. 1. 0. 2. 2. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 0. 3. 1. 2. 1. 1. 0. 2. 1. 1. 1. 2. 0. 0. 1. 0. 3. 3. 3. 3. 3. 3.\n",
            " 2. 0. 0. 2. 2. 0. 3. 2. 2. 1. 0. 0. 0. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 1. 2. 2. 2. 0. 3. 3. 3. 3. 1. 3. 0. 1. 1. 3. 1. 0. 3. 3. 0. 2. 3.\n",
            " 2. 0. 2. 1. 0. 1. 3. 0. 2. 2. 0. 3. 0. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 0. 3. 2. 1. 1. 3. 3. 2. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 2. 0. 2. 0.\n",
            " 1. 0. 3. 3. 2. 0. 2. 3. 0. 3. 0. 2. 3. 0. 1. 1. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 1. 3. 3. 2. 3. 0. 2. 3. 1. 0. 3. 3. 1. 1. 1. 1.\n",
            " 1. 0. 0. 1. 0. 0. 2. 2. 3. 0. 2. 1. 2. 2. 3. 2. 0. 3. 0. 3. 3. 2. 0. 0.\n",
            " 0. 2. 2. 1. 1. 3. 3. 1. 1. 1. 1. 2. 0. 0. 1. 1. 0. 0. 2. 0. 0. 2. 1. 2.\n",
            " 0. 2. 3. 2. 2. 1. 0. 1. 2. 2. 0. 1. 1. 0. 2. 2. 2. 2. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 1. 3. 1. 0. 0. 3. 0. 2. 3. 1. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 2.\n",
            " 1. 3. 2. 2. 1. 3. 2. 1. 2. 1. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 2. 2. 0. 2.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 2. 2. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 2. 2.\n",
            " 3. 1. 3. 1. 2. 1. 2. 1. 0. 1. 1. 1. 1. 0. 1. 3. 1. 3. 3. 2. 2. 2. 2. 2.\n",
            " 0. 0. 1. 1. 0. 0. 0. 0. 0. 2. 3. 2. 0. 3. 1. 2. 2. 2. 1. 2. 0. 0. 3. 2.\n",
            " 1. 1. 3. 2. 0. 1. 0. 0. 2. 1. 1. 1. 0. 3. 2. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 2. 1. 2. 3. 0. 0. 3. 1. 2. 3. 3. 3. 3. 0. 0. 0. 1. 3. 0. 0. 2. 1. 3. 1.\n",
            " 2. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 2. 0. 2. 1. 1. 3. 3. 1. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 0. 1. 1. 1. 3. 3. 1. 3. 2.\n",
            " 2. 2. 3. 1. 3. 2. 2. 2. 1. 3. 2. 3. 1. 1. 2. 0. 1. 1. 1. 2. 2. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 0. 1. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 2. 2. 1. 0. 1. 2. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 2. 2. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 0. 2.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 2. 2. 2. 1. 0. 3. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 2. 1. 1. 1. 1. 2. 0. 2. 1. 0. 1. 2. 0. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 2. 2. 1. 1. 0. 0. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 0. 3. 2. 2. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 3. 1. 0. 2. 3. 1. 2. 3.\n",
            " 3. 0. 2. 2. 0. 0. 3. 0. 2. 2. 0. 3. 0. 2. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 1. 1. 3. 3. 3. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 1. 1. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 3. 2. 2. 2. 3. 2. 3. 0. 2. 3. 1. 0. 3. 3. 0. 1. 1. 0.\n",
            " 1. 0. 0. 1. 2. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 3. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 0. 2. 0. 0. 0. 2. 0. 0. 2. 1. 3.\n",
            " 0. 2. 3. 2. 2. 1. 0. 2. 3. 2. 0. 1. 1. 0. 2. 2. 2. 3. 3. 2. 2. 2. 1. 1.\n",
            " 3. 1. 2. 1. 3. 1. 0. 0. 3. 0. 2. 3. 2. 0. 2. 0. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 2. 3. 0. 0. 0. 1. 3. 0. 2. 2. 0. 2. 2. 0. 1.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 2. 0. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 0. 2. 1. 1. 1. 1. 1. 3. 2. 3. 3. 2. 1. 2. 1. 3.\n",
            " 1. 0. 1. 2. 1. 1. 0. 1. 0. 2. 3. 2. 0. 3. 1. 2. 3. 2. 1. 2. 0. 1. 2. 3.\n",
            " 1. 1. 3. 2. 1. 1. 0. 0. 2. 1. 1. 1. 0. 3. 2. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 2. 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 0. 0. 1. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 2. 1. 3. 2. 3. 1. 2. 1. 3. 1. 0. 0. 3. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 2. 3. 3. 3. 1. 0. 2. 0. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 3. 2. 1. 2. 1. 3. 2. 3. 1. 1. 2. 2. 1. 1. 1. 3. 2. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 2. 2. 0. 0. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 2. 2. 1. 0. 0. 1. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 3. 0. 2. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 3. 1. 1. 3. 0. 0. 1. 2. 0. 0. 0. 1. 2.\n",
            " 0. 2. 0. 1. 1. 1. 1. 1. 0. 3. 3. 1. 1. 2. 0. 0. 1. 0. 3. 2. 3. 2. 3. 3.\n",
            " 1. 0. 0. 2. 3. 0. 3. 2. 2. 1. 1. 0. 0. 0. 3. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 0. 2. 2. 1. 0. 3. 2. 1. 3. 1. 3. 0. 1. 1. 3. 1. 0. 2. 3. 0. 1. 3.\n",
            " 3. 0. 2. 1. 0. 1. 3. 0. 2. 3. 2. 3. 0. 1. 2. 0. 2. 1. 0. 0. 2. 3. 0. 2.\n",
            " 3. 2. 3. 3. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 1. 1. 3. 2. 2. 1. 3. 0. 2. 1. 3. 0. 3. 0. 3. 1. 1. 2. 1.\n",
            " 1. 0. 2. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 2. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 3. 2. 2. 3. 1. 3. 0. 2. 3. 1. 0. 3. 3. 0. 1. 1. 1.\n",
            " 2. 0. 0. 0. 2. 1. 1. 2. 3. 1. 1. 1. 3. 3. 3. 2. 0. 3. 1. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 3. 1. 2.\n",
            " 0. 2. 3. 2. 2. 1. 0. 2. 3. 2. 0. 1. 1. 0. 2. 2. 2. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 0. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 2. 0. 3. 2. 0. 2. 2. 0. 0.\n",
            " 1. 3. 1. 1. 1. 3. 1. 0. 3. 1. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 0. 1. 2. 1. 0. 1. 1. 1. 2. 1. 1. 2. 1. 2. 3. 1. 2. 2. 1. 2.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 2. 2. 2. 0. 3. 1. 2. 2. 2. 1. 3. 0. 1. 2. 3.\n",
            " 1. 1. 3. 2. 0. 1. 1. 0. 2. 1. 2. 1. 0. 2. 2. 2. 2. 0. 3. 0. 3. 2. 2. 0.\n",
            " 2. 1. 2. 3. 0. 0. 2. 1. 1. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 3. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 2. 0. 0. 3. 0. 1. 1. 1. 3. 3. 2. 3. 3.\n",
            " 2. 2. 2. 1. 2. 2. 1. 2. 1. 3. 2. 3. 1. 1. 2. 0. 1. 2. 1. 3. 3. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 3. 2. 1. 1. 1. 2. 2. 2. 2. 0. 1. 3. 0. 0. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 3. 1. 1. 0. 2. 2. 1. 1. 3. 1. 0. 0. 1. 1. 3. 2.\n",
            " 2. 3. 3. 2. 1. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 2. 0. 1.\n",
            " 1. 0. 1. 2. 0. 0. 1. 2. 3. 2. 2. 3. 1. 0. 3. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 0. 2. 2. 0. 1. 1. 1. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 2. 3. 2. 2. 2. 1. 0. 0. 0. 3. 2. 1. 3. 2. 3. 0. 2. 2. 0.\n",
            " 1. 0. 0. 3. 2. 0. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 3. 1. 0. 3. 2. 0. 2. 3.\n",
            " 3. 0. 3. 1. 0. 1. 3. 0. 3. 3. 0. 3. 0. 1. 0. 0. 2. 0. 0. 2. 2. 3. 2. 1.\n",
            " 2. 2. 3. 0. 3. 0. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 2. 0. 0.\n",
            " 2. 2. 1. 3. 2. 1. 1. 3. 3. 3. 1. 3. 3. 0. 1. 2. 1. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 2. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 1. 2. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 1. 3. 3. 3. 3. 0. 1. 3. 1. 0. 2. 3. 0. 1. 0. 1.\n",
            " 2. 0. 0. 0. 2. 1. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 3. 3. 2. 0. 1.\n",
            " 0. 3. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 1. 1. 0. 3. 0. 2. 0. 0. 2. 1. 2.\n",
            " 0. 1. 3. 3. 2. 1. 0. 1. 2. 2. 0. 1. 2. 1. 2. 2. 2. 3. 3. 3. 2. 2. 1. 1.\n",
            " 3. 1. 1. 1. 2. 0. 0. 0. 3. 0. 2. 0. 3. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 1. 1. 2. 2. 1. 2. 3. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 3. 2. 0. 1.\n",
            " 1. 3. 1. 1. 2. 0. 0. 0. 2. 1. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 3. 0. 2. 1. 1. 2. 1. 1. 3. 0. 3. 0. 2. 1. 2. 1. 2.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 0. 2. 3. 2. 0. 3. 1. 3. 2. 2. 2. 2. 0. 1. 2. 3.\n",
            " 1. 1. 3. 0. 0. 1. 0. 0. 2. 1. 3. 1. 0. 3. 0. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 2. 1. 2. 2. 0. 1. 3. 1. 1. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 3. 2. 1. 3. 1.\n",
            " 3. 3. 3. 3. 3. 1. 3. 1. 3. 1. 0. 0. 0. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 2. 3. 2. 3. 1. 0. 2. 0. 1. 1. 1. 3. 3. 3. 3. 3.\n",
            " 2. 2. 3. 1. 3. 2. 2. 2. 2. 3. 2. 3. 1. 1. 2. 0. 1. 1. 2. 3. 2. 2. 3. 3.]\n",
            "[1. 0. 2. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 1. 0. 3. 0. 1. 0. 2. 0. 1. 1. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 0. 0. 1. 0. 1. 2. 2. 1. 0. 1. 1. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 3. 0. 2. 3. 0. 1. 3. 1. 1.\n",
            " 1. 2. 0. 0. 0. 0. 1. 3. 0. 2. 2. 3. 2. 0. 3. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
            " 0. 2. 1. 1. 1. 1. 3. 2. 1. 3. 1. 1. 0. 2. 0. 0. 1. 0. 3. 3. 3. 2. 2. 3.\n",
            " 2. 0. 0. 2. 2. 0. 3. 2. 2. 1. 1. 0. 0. 0. 3. 2. 1. 3. 2. 3. 0. 1. 2. 0.\n",
            " 1. 0. 1. 3. 2. 2. 0. 3. 2. 3. 3. 1. 3. 0. 0. 1. 3. 1. 0. 2. 3. 0. 2. 2.\n",
            " 3. 0. 2. 1. 0. 1. 3. 0. 2. 3. 3. 3. 0. 1. 2. 0. 2. 0. 0. 0. 3. 3. 0. 0.\n",
            " 2. 2. 3. 3. 1. 1. 2. 0. 0. 2. 0. 2. 1. 0. 3. 3. 0. 2. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 1. 0. 3. 3. 3. 2. 3. 0. 3. 1. 3. 1. 3. 0. 0. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 2. 0. 2. 3. 0. 1. 0. 2. 2. 0. 2. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 1. 2. 0. 1. 1. 3. 0. 2. 3. 2. 3. 3. 3. 1. 2. 1. 1.\n",
            " 1. 0. 0. 1. 3. 1. 2. 2. 0. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 2. 0. 2.\n",
            " 0. 1. 3. 2. 2. 1. 0. 3. 2. 2. 3. 2. 0. 1. 1. 2. 2. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 3. 0. 2. 2. 0. 2. 3. 0. 1.\n",
            " 3. 1. 1. 2. 1. 3. 0. 1. 3. 1. 2. 3. 1. 1. 3. 3. 1. 0. 3. 1. 3. 1. 1. 2.\n",
            " 3. 3. 2. 2. 1. 1. 2. 0. 0. 1. 1. 1. 2. 1. 2. 3. 1. 3. 3. 1. 2. 3. 1. 2.\n",
            " 1. 0. 0. 1. 1. 1. 0. 0. 0. 2. 3. 2. 2. 3. 1. 2. 2. 2. 0. 1. 0. 1. 3. 2.\n",
            " 1. 1. 3. 2. 0. 1. 1. 0. 1. 1. 2. 1. 0. 3. 2. 2. 2. 0. 2. 2. 3. 2. 2. 3.\n",
            " 2. 1. 2. 2. 0. 0. 3. 1. 1. 3. 3. 3. 3. 1. 0. 1. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 2. 0. 1. 0. 3. 2. 3. 2. 2. 3.\n",
            " 3. 3. 2. 0. 1. 3. 1. 0. 3. 3. 3. 2. 1. 0. 2. 0. 0. 1. 1. 3. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 3. 2. 2. 1. 1. 3. 1. 3. 1. 1. 2. 0. 1. 1. 1. 2. 2. 2. 3. 0.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 1. 2. 0. 1. 3. 0. 1. 0. 3. 0. 0. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 2. 2. 1. 1. 0. 0. 3. 1. 0. 1. 0. 1. 2.\n",
            " 3. 3. 3. 3. 1. 2. 1. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 2. 0. 1. 0. 0. 3. 2. 2. 1. 0. 3. 2. 0. 1. 1. 0. 0. 1. 2. 1.\n",
            " 0. 3. 1. 1. 1. 2. 1. 2. 0. 2. 2. 1. 2. 2. 0. 0. 3. 0. 3. 3. 1. 2. 3. 3.\n",
            " 2. 0. 0. 2. 2. 0. 3. 2. 2. 1. 1. 0. 3. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 0. 2. 2. 2. 0. 3. 2. 3. 2. 1. 3. 0. 1. 1. 3. 1. 0. 1. 3. 1. 2. 3.\n",
            " 3. 0. 2. 1. 0. 1. 3. 0. 2. 2. 0. 3. 0. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 3. 2. 3. 3. 3. 1. 3. 2. 0. 2. 0. 1. 1. 0. 3. 3. 1. 3. 0. 1. 2. 0. 3. 0.\n",
            " 2. 0. 1. 2. 2. 1. 1. 3. 3. 3. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 1. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 1. 3. 0. 1. 3. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 1. 2. 3. 3. 2. 3. 0. 2. 3. 1. 0. 3. 3. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 2. 3. 1. 2. 3. 3. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 2. 0. 2. 1. 2. 3. 1. 1. 1. 1. 2. 1. 0. 3. 0. 0. 0. 2. 0. 0. 2. 1. 2.\n",
            " 0. 1. 3. 2. 2. 1. 3. 1. 3. 2. 0. 1. 1. 0. 1. 0. 1. 2. 3. 2. 2. 2. 1. 1.\n",
            " 3. 0. 2. 1. 3. 0. 1. 0. 3. 0. 3. 3. 2. 0. 1. 0. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 2. 2. 2. 1. 2. 1. 3. 0. 0. 1. 1. 2. 0. 3. 2. 1. 2. 1. 0. 1.\n",
            " 1. 3. 1. 0. 1. 3. 0. 1. 2. 1. 1. 3. 1. 1. 3. 2. 0. 0. 0. 2. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 0. 2. 1. 0. 2. 0. 1. 3. 1. 3. 3. 2. 1. 2. 2. 2.\n",
            " 2. 1. 1. 1. 1. 1. 0. 1. 1. 1. 3. 2. 0. 3. 1. 2. 2. 2. 0. 2. 1. 1. 2. 3.\n",
            " 1. 1. 3. 1. 0. 1. 0. 0. 2. 1. 1. 1. 1. 3. 2. 2. 3. 0. 3. 2. 3. 2. 2. 2.\n",
            " 1. 1. 2. 2. 0. 0. 3. 1. 1. 3. 3. 2. 3. 0. 0. 0. 2. 3. 0. 0. 3. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 0. 3. 1. 3. 0. 0. 0. 3. 0. 2. 3. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 1. 3. 3. 1. 0. 2. 1. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 1. 2. 3. 1. 3. 2. 3. 2. 1. 3. 2. 3. 1. 1. 2. 1. 1. 1. 2. 3. 2. 2. 3. 3.]\n",
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0]\n",
            "testing target data: 855     1\n",
            "635     1\n",
            "396     3\n",
            "1816    3\n",
            "1213    1\n",
            "       ..\n",
            "1041    3\n",
            "1799    2\n",
            "1330    2\n",
            "242     3\n",
            "850     3\n",
            "Name: price_range, Length: 600, dtype: int64\n",
            "Accuracy: 0.9816666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most repeated accuracy selection-Mode\n",
        "Average accuracy selection-mean\n",
        "Choosing the middle value after sorting the accuracy-median\n",
        "Apart from accuracy-what else can be chosen for performance evaluation in decision tree???\n",
        "Next step? Pruning? How to evaluate performance after pruning?\n"
      ],
      "metadata": {
        "id": "E7zbgf29hYWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prf1.info"
      ],
      "metadata": {
        "id": "p5RoK52lis_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bebc3be2-4109-4b8e-9612-55396eb4a44a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'accuracy': 0.7675, 'cluster_idx': 3},\n",
              " 1: {'accuracy': 0.5575, 'cluster_idx': 1},\n",
              " 2: {'accuracy': 0.5805, 'cluster_idx': 5},\n",
              " 3: {'accuracy': 0.6385000000000001, 'cluster_idx': 5},\n",
              " 4: {'accuracy': 0.562, 'cluster_idx': 2},\n",
              " 5: {'accuracy': 0.627, 'cluster_idx': 0},\n",
              " 6: {'accuracy': 0.6174999999999999, 'cluster_idx': 0},\n",
              " 7: {'accuracy': 0.534, 'cluster_idx': 0},\n",
              " 8: {'accuracy': 0.624, 'cluster_idx': 5},\n",
              " 9: {'accuracy': 0.617, 'cluster_idx': 4},\n",
              " 10: {'accuracy': 0.662, 'cluster_idx': 3},\n",
              " 11: {'accuracy': 0.7324999999999999, 'cluster_idx': 3},\n",
              " 12: {'accuracy': 0.5885, 'cluster_idx': 0},\n",
              " 13: {'accuracy': 0.6905, 'cluster_idx': 0},\n",
              " 14: {'accuracy': 0.5774999999999999, 'cluster_idx': 0},\n",
              " 15: {'accuracy': 0.5415, 'cluster_idx': 0},\n",
              " 16: {'accuracy': 0.5814999999999999, 'cluster_idx': 1},\n",
              " 17: {'accuracy': 0.5545, 'cluster_idx': 2},\n",
              " 18: {'accuracy': 0.6125, 'cluster_idx': 0},\n",
              " 19: {'accuracy': 0.603, 'cluster_idx': 5},\n",
              " 20: {'accuracy': 0.7420000000000001, 'cluster_idx': 1},\n",
              " 21: {'accuracy': 0.6100000000000001, 'cluster_idx': 5},\n",
              " 22: {'accuracy': 0.721, 'cluster_idx': 1},\n",
              " 23: {'accuracy': 0.5655, 'cluster_idx': 0},\n",
              " 24: {'accuracy': 0.652, 'cluster_idx': 1},\n",
              " 25: {'accuracy': 0.6495, 'cluster_idx': 1},\n",
              " 26: {'accuracy': 0.631, 'cluster_idx': 1},\n",
              " 27: {'accuracy': 0.5325, 'cluster_idx': 2},\n",
              " 28: {'accuracy': 0.614, 'cluster_idx': 1},\n",
              " 29: {'accuracy': 0.721, 'cluster_idx': 3},\n",
              " 30: {'accuracy': 0.643, 'cluster_idx': 1},\n",
              " 31: {'accuracy': 0.5654999999999999, 'cluster_idx': 4},\n",
              " 32: {'accuracy': 0.686, 'cluster_idx': 1},\n",
              " 33: {'accuracy': 0.6344999999999998, 'cluster_idx': 5},\n",
              " 34: {'accuracy': 0.5855, 'cluster_idx': 1},\n",
              " 35: {'accuracy': 0.6994999999999999, 'cluster_idx': 1},\n",
              " 36: {'accuracy': 0.6195, 'cluster_idx': 1},\n",
              " 37: {'accuracy': 0.6475, 'cluster_idx': 1},\n",
              " 38: {'accuracy': 0.6980000000000001, 'cluster_idx': 3},\n",
              " 39: {'accuracy': 0.709, 'cluster_idx': 1},\n",
              " 40: {'accuracy': 0.688, 'cluster_idx': 1},\n",
              " 41: {'accuracy': 0.642, 'cluster_idx': 3},\n",
              " 42: {'accuracy': 0.7499999999999999, 'cluster_idx': 1},\n",
              " 43: {'accuracy': 0.744, 'cluster_idx': 3},\n",
              " 44: {'accuracy': 0.555, 'cluster_idx': 2},\n",
              " 45: {'accuracy': 0.6345, 'cluster_idx': 2},\n",
              " 46: {'accuracy': 0.6599999999999999, 'cluster_idx': 5},\n",
              " 47: {'accuracy': 0.526, 'cluster_idx': 0},\n",
              " 48: {'accuracy': 0.5834999999999999, 'cluster_idx': 2},\n",
              " 49: {'accuracy': 0.5745, 'cluster_idx': 3},\n",
              " 50: {'accuracy': 0.7005, 'cluster_idx': 1},\n",
              " 51: {'accuracy': 0.73, 'cluster_idx': 1},\n",
              " 52: {'accuracy': 0.7265, 'cluster_idx': 3},\n",
              " 53: {'accuracy': 0.6829999999999999, 'cluster_idx': 3},\n",
              " 54: {'accuracy': 0.623, 'cluster_idx': 2},\n",
              " 55: {'accuracy': 0.615, 'cluster_idx': 2},\n",
              " 56: {'accuracy': 0.651, 'cluster_idx': 1},\n",
              " 57: {'accuracy': 0.6565000000000001, 'cluster_idx': 5},\n",
              " 58: {'accuracy': 0.619, 'cluster_idx': 4},\n",
              " 59: {'accuracy': 0.5965, 'cluster_idx': 5},\n",
              " 60: {'accuracy': 0.6024999999999999, 'cluster_idx': 2},\n",
              " 61: {'accuracy': 0.655, 'cluster_idx': 5},\n",
              " 62: {'accuracy': 0.581, 'cluster_idx': 1},\n",
              " 63: {'accuracy': 0.5465, 'cluster_idx': 5},\n",
              " 64: {'accuracy': 0.6950000000000001, 'cluster_idx': 3},\n",
              " 65: {'accuracy': 0.634, 'cluster_idx': 0},\n",
              " 66: {'accuracy': 0.7215, 'cluster_idx': 5},\n",
              " 67: {'accuracy': 0.663, 'cluster_idx': 2},\n",
              " 68: {'accuracy': 0.6375, 'cluster_idx': 5},\n",
              " 69: {'accuracy': 0.5665, 'cluster_idx': 5},\n",
              " 70: {'accuracy': 0.5825000000000001, 'cluster_idx': 3},\n",
              " 71: {'accuracy': 0.6655, 'cluster_idx': 1},\n",
              " 72: {'accuracy': 0.741, 'cluster_idx': 3},\n",
              " 73: {'accuracy': 0.647, 'cluster_idx': 4},\n",
              " 74: {'accuracy': 0.7325000000000002, 'cluster_idx': 1},\n",
              " 75: {'accuracy': 0.737, 'cluster_idx': 1},\n",
              " 76: {'accuracy': 0.6315000000000001, 'cluster_idx': 2},\n",
              " 77: {'accuracy': 0.5740000000000001, 'cluster_idx': 5},\n",
              " 78: {'accuracy': 0.7074999999999999, 'cluster_idx': 3},\n",
              " 79: {'accuracy': 0.5974999999999999, 'cluster_idx': 2},\n",
              " 80: {'accuracy': 0.7084999999999999, 'cluster_idx': 1},\n",
              " 81: {'accuracy': 0.6935, 'cluster_idx': 3},\n",
              " 82: {'accuracy': 0.5984999999999999, 'cluster_idx': 5},\n",
              " 83: {'accuracy': 0.651, 'cluster_idx': 2},\n",
              " 84: {'accuracy': 0.708, 'cluster_idx': 5},\n",
              " 85: {'accuracy': 0.6675, 'cluster_idx': 5},\n",
              " 86: {'accuracy': 0.718, 'cluster_idx': 1},\n",
              " 87: {'accuracy': 0.579, 'cluster_idx': 1},\n",
              " 88: {'accuracy': 0.564, 'cluster_idx': 4},\n",
              " 89: {'accuracy': 0.5625, 'cluster_idx': 5},\n",
              " 90: {'accuracy': 0.638, 'cluster_idx': 2},\n",
              " 91: {'accuracy': 0.5745, 'cluster_idx': 1},\n",
              " 92: {'accuracy': 0.6054999999999999, 'cluster_idx': 0},\n",
              " 93: {'accuracy': 0.5974999999999999, 'cluster_idx': 5},\n",
              " 94: {'accuracy': 0.5814999999999999, 'cluster_idx': 0},\n",
              " 95: {'accuracy': 0.6745, 'cluster_idx': 0},\n",
              " 96: {'accuracy': 0.6955000000000001, 'cluster_idx': 1},\n",
              " 97: {'accuracy': 0.557, 'cluster_idx': 0},\n",
              " 98: {'accuracy': 0.6805000000000001, 'cluster_idx': 3},\n",
              " 99: {'accuracy': 0.6245, 'cluster_idx': 5}}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6Y8_j6BElPT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1e90bf-1115-44f8-e91b-354d2345dbe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'3': [0], '1': [42], '5': [66], '2': [67], '0': [13], '4': [73]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'3': 0}\n",
            "{'1': 42}\n",
            "{'5': 66}\n",
            "{'2': 67}\n",
            "{'0': 13}\n",
            "{'4': 73}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': [13], '1': [42], '2': [67], '3': [0], '4': [73], '5': [66]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#dbscan\n",
        "getMaxAccuracyCluster(prf1.info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf1.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf1)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "print(y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))"
      ],
      "metadata": {
        "id": "bX5EdMw-AXHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97175784-5881-458d-fa50-dbd8da01e1e0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'3': [0], '1': [42], '5': [66], '2': [67], '0': [13], '4': [73]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'3': 0}\n",
            "{'1': 42}\n",
            "{'5': 66}\n",
            "{'2': 67}\n",
            "{'0': 13}\n",
            "{'4': 73}\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 3. 2. 2. 0. 1. 3. 0. 1. 0. 3. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 0. 0. 2. 2. 1. 0. 0. 1. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 3. 3. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 3. 1. 0. 2. 0. 0. 1. 1. 0. 0. 1. 1. 2.\n",
            " 0. 3. 1. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 0. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 2. 2. 1. 1. 0. 0. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 1. 2. 2. 1. 0. 2. 2. 3. 2. 1. 3. 0. 0. 1. 3. 1. 0. 2. 3. 1. 2. 3.\n",
            " 3. 0. 2. 1. 0. 1. 2. 0. 2. 3. 0. 3. 0. 1. 3. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 0. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 2. 2. 0. 0. 0.\n",
            " 2. 0. 0. 2. 2. 1. 1. 3. 3. 3. 1. 3. 0. 3. 1. 2. 1. 2. 1. 3. 2. 1. 2. 1.\n",
            " 1. 0. 2. 3. 2. 0. 3. 3. 0. 2. 0. 2. 3. 0. 2. 0. 1. 2. 0. 2. 1. 1. 1. 0.\n",
            " 3. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 2. 3. 1. 0. 3. 3. 1. 1. 1. 1.\n",
            " 2. 0. 0. 1. 2. 2. 2. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 2. 1. 3. 3. 1. 1. 3. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 2. 1. 2.\n",
            " 0. 2. 3. 2. 2. 1. 0. 2. 2. 2. 0. 1. 2. 0. 2. 2. 2. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 3. 3. 0. 2. 1. 1. 3. 1. 2. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 3. 0. 2. 2. 0. 2. 2. 0. 1.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 2. 0. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 1. 0. 2. 1.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 0. 1. 1. 1. 2. 1. 1. 3. 1. 3. 2. 2. 2. 3. 1. 2.\n",
            " 0. 0. 1. 1. 1. 1. 0. 1. 0. 2. 3. 2. 0. 3. 1. 3. 2. 2. 1. 2. 0. 1. 3. 2.\n",
            " 1. 1. 3. 2. 0. 1. 0. 0. 2. 1. 1. 0. 0. 2. 2. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 2. 1. 1. 2. 0. 0. 3. 1. 1. 3. 3. 2. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 3. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 2. 2. 2. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 2. 3. 3. 3. 1. 0. 3. 0. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 2. 2. 3. 2. 1. 3. 2. 3. 0. 1. 2. 0. 1. 1. 1. 3. 2. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 0. 1. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 2. 2. 1. 0. 0. 2. 0. 0. 0. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 2. 2. 3. 3. 0. 0. 3. 2. 1. 3. 3. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 2. 0. 0. 1. 2. 3. 1. 0. 3. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 0. 3. 2. 1. 1. 2. 0. 0. 1. 0. 3. 2. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 2. 2. 2. 1. 1. 0. 0. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 0. 2. 2. 2. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 3. 1. 0. 2. 3. 0. 2. 3.\n",
            " 3. 0. 2. 1. 0. 1. 3. 0. 1. 3. 0. 3. 0. 2. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 1. 3. 1. 2. 2. 1. 2. 0. 1. 1. 0. 3. 3. 2. 3. 1. 2. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 3. 1. 1. 3. 2. 3. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 2. 1. 2. 0.\n",
            " 0. 0. 3. 2. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 3. 0. 3. 1. 1. 1. 0.\n",
            " 1. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 2. 3. 0. 0. 3. 3. 1. 1. 2. 1.\n",
            " 2. 0. 0. 0. 2. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 2. 0. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 0. 0. 3. 0. 0. 2. 1. 3.\n",
            " 0. 1. 3. 2. 2. 1. 0. 2. 3. 2. 1. 1. 0. 0. 2. 2. 2. 2. 3. 1. 3. 2. 1. 1.\n",
            " 2. 1. 2. 1. 3. 0. 0. 0. 3. 0. 3. 2. 1. 0. 2. 1. 2. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 1. 2. 2. 2. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 2. 1. 0. 0.\n",
            " 1. 3. 1. 1. 0. 3. 0. 0. 1. 0. 1. 3. 2. 1. 3. 2. 1. 0. 1. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 0. 2. 1. 1. 2. 1. 1. 3. 1. 2. 3. 2. 3. 2. 1. 2.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 0. 2. 3. 2. 0. 3. 1. 2. 3. 2. 1. 2. 0. 1. 3. 2.\n",
            " 1. 2. 2. 2. 1. 1. 0. 0. 2. 1. 1. 1. 0. 3. 2. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 1. 1. 2. 2. 0. 0. 3. 0. 1. 3. 2. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 2. 1. 0. 0. 3. 0. 2. 2. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 2. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 1. 1. 1. 1. 3. 3. 2. 3. 3.\n",
            " 2. 2. 3. 1. 3. 1. 2. 2. 1. 3. 2. 3. 1. 1. 2. 1. 1. 2. 0. 3. 1. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 2. 2. 1. 0. 2. 2. 1. 2. 3. 0. 1. 3. 0. 0. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 2. 0. 2. 3. 2. 1. 0. 1. 1. 0. 2. 2. 1. 0. 1. 2. 0. 0. 0. 0. 3. 2.\n",
            " 3. 2. 3. 3. 1. 2. 0. 1. 2. 2. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 2. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 3. 1. 0. 3. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 1. 3. 0. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 0. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 3. 1. 1. 1. 0. 0. 0. 3. 2. 1. 3. 2. 3. 0. 3. 3. 0.\n",
            " 1. 0. 0. 2. 3. 2. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 3. 1. 0. 2. 2. 0. 2. 3.\n",
            " 3. 0. 1. 1. 0. 2. 3. 0. 2. 3. 0. 3. 0. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 0.\n",
            " 2. 2. 3. 3. 3. 0. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 2. 2. 0. 0. 1.\n",
            " 2. 0. 1. 3. 2. 1. 1. 3. 2. 3. 1. 3. 1. 3. 1. 3. 1. 3. 0. 2. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 2. 3. 1. 0. 3. 3. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 2. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 2. 3. 3. 1. 1. 1. 1. 2. 1. 1. 1. 0. 0. 0. 2. 0. 0. 2. 1. 2.\n",
            " 0. 1. 3. 2. 2. 1. 0. 2. 3. 3. 0. 1. 1. 0. 2. 2. 2. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 1. 3. 0. 1. 0. 3. 0. 2. 3. 3. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 0. 2. 2. 0. 2. 1. 2. 0. 1. 0. 1. 2. 1. 2. 2. 1. 2. 2. 1. 1.\n",
            " 1. 3. 1. 1. 0. 3. 0. 0. 2. 0. 2. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 1. 2. 1. 1. 2. 1. 1. 3. 1. 3. 2. 2. 2. 2. 1. 2.\n",
            " 1. 0. 1. 1. 1. 1. 0. 2. 0. 2. 3. 2. 0. 3. 1. 2. 2. 2. 1. 2. 0. 1. 3. 2.\n",
            " 1. 1. 1. 2. 0. 2. 1. 0. 2. 1. 0. 1. 0. 2. 2. 1. 2. 0. 3. 1. 3. 2. 2. 0.\n",
            " 2. 1. 2. 2. 0. 0. 3. 1. 1. 3. 3. 3. 3. 0. 0. 0. 1. 3. 0. 1. 2. 1. 3. 1.\n",
            " 3. 2. 3. 2. 3. 1. 3. 1. 3. 0. 0. 1. 3. 0. 2. 1. 1. 3. 3. 0. 3. 0. 3. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 0. 0. 2. 0. 3. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 3. 2. 2. 3. 1. 3. 2. 3. 1. 1. 2. 0. 1. 1. 1. 3. 2. 2. 2. 3.]\n",
            "[0. 0. 3. 3. 1. 2. 1. 0. 2. 3. 2. 2. 2. 0. 1. 3. 0. 1. 0. 2. 0. 1. 3. 1.\n",
            " 3. 1. 3. 0. 2. 3. 0. 1. 0. 1. 2. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 2.\n",
            " 3. 2. 3. 2. 1. 2. 0. 2. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 2. 3. 0. 0.\n",
            " 1. 0. 0. 0. 0. 2. 1. 0. 0. 1. 2. 3. 2. 2. 2. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 2. 1. 2. 2. 1. 2. 0. 2. 1. 1. 1. 2. 0. 0. 1. 0. 3. 2. 3. 1. 3. 3.\n",
            " 2. 0. 0. 2. 1. 0. 3. 2. 2. 1. 1. 0. 1. 2. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 0. 2. 2. 1. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 3. 0. 0. 2. 3. 0. 2. 3.\n",
            " 3. 0. 3. 1. 0. 1. 3. 0. 2. 1. 0. 3. 0. 2. 0. 0. 2. 0. 0. 0. 0. 3. 0. 0.\n",
            " 2. 2. 3. 3. 3. 1. 0. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 2. 1. 1. 1. 3. 3. 3. 1. 3. 0. 3. 1. 3. 1. 3. 0. 2. 0. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 3. 0. 1. 1. 0. 1. 0.\n",
            " 2. 1. 0. 1. 3. 3. 2. 2. 3. 2. 3. 2. 3. 1. 2. 3. 1. 2. 3. 3. 0. 1. 1. 1.\n",
            " 2. 0. 0. 1. 2. 2. 1. 0. 3. 0. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 1. 1. 1. 0. 3. 2. 1. 1. 1. 1. 2. 1. 0. 3. 0. 2. 0. 2. 1. 0. 2. 1. 2.\n",
            " 0. 1. 3. 2. 2. 0. 0. 1. 2. 0. 0. 1. 1. 0. 2. 2. 2. 3. 3. 2. 0. 1. 1. 3.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 3. 3. 2. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 1. 1. 2. 1. 3. 2. 0. 0. 1. 1. 2. 2. 2. 0. 2. 1. 0. 1.\n",
            " 1. 3. 1. 1. 0. 3. 0. 0. 2. 1. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 2. 1. 3. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 3. 1. 3. 3. 2. 3. 2. 1. 3.\n",
            " 2. 0. 1. 1. 2. 1. 0. 1. 0. 2. 3. 1. 0. 3. 0. 2. 2. 2. 1. 2. 0. 2. 2. 2.\n",
            " 1. 1. 3. 2. 0. 2. 0. 1. 2. 1. 0. 1. 0. 2. 2. 2. 2. 0. 3. 0. 3. 2. 2. 2.\n",
            " 2. 1. 0. 2. 0. 0. 3. 1. 1. 3. 1. 3. 3. 0. 0. 0. 2. 3. 0. 1. 2. 1. 3. 1.\n",
            " 1. 1. 3. 2. 3. 1. 3. 1. 1. 1. 0. 0. 3. 0. 3. 1. 1. 3. 3. 0. 3. 0. 1. 3.\n",
            " 1. 3. 2. 1. 1. 3. 2. 0. 3. 3. 2. 3. 1. 0. 3. 0. 2. 1. 1. 3. 3. 2. 3. 2.\n",
            " 1. 2. 3. 1. 3. 3. 2. 2. 1. 3. 2. 2. 3. 2. 2. 1. 1. 1. 1. 0. 2. 2. 3. 3.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 3. 3. 1. 3. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 1. 0. 0. 3. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 0. 0. 1. 1. 0. 2. 2. 1. 0. 0. 1. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 2. 0. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 2. 0. 1.\n",
            " 1. 1. 0. 0. 0. 0. 1. 0. 0. 2. 2. 3. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 2.\n",
            " 0. 2. 1. 1. 1. 1. 1. 3. 1. 3. 1. 1. 1. 2. 0. 2. 1. 0. 3. 3. 2. 3. 3. 3.\n",
            " 2. 0. 0. 3. 3. 0. 3. 2. 2. 1. 1. 0. 1. 0. 2. 2. 1. 3. 3. 3. 0. 2. 3. 0.\n",
            " 1. 0. 1. 2. 2. 0. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 1. 1. 0. 3. 3. 1. 2. 3.\n",
            " 3. 0. 0. 1. 0. 2. 2. 0. 2. 3. 0. 3. 0. 1. 2. 1. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 3. 3. 2. 3. 1. 1. 2. 0. 2. 0. 1. 1. 0. 2. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 1. 0. 1. 3. 2. 1. 1. 3. 3. 2. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 3. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 2. 0. 3. 0. 1. 3. 0. 1. 0. 2. 2. 0. 3. 2. 0. 0. 0.\n",
            " 2. 1. 1. 0. 3. 3. 2. 3. 2. 2. 2. 2. 3. 1. 2. 3. 0. 0. 3. 3. 0. 1. 1. 2.\n",
            " 1. 0. 0. 1. 2. 2. 1. 2. 3. 1. 0. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 1. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 2. 0. 1. 0. 1. 1. 3. 1. 0. 2. 1. 3.\n",
            " 1. 1. 3. 2. 2. 0. 1. 2. 2. 2. 0. 1. 1. 0. 2. 1. 2. 3. 3. 1. 2. 2. 0. 1.\n",
            " 3. 1. 2. 0. 3. 0. 1. 0. 3. 0. 2. 2. 3. 0. 2. 1. 1. 3. 1. 3. 1. 1. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 2. 2. 1. 3. 0. 0. 0. 1. 3. 0. 2. 2. 0. 2. 1. 1. 0.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 3. 1. 0. 3. 1. 1. 3. 2. 0. 0. 0. 1. 2. 0. 2. 0.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 0. 1. 1. 1. 2. 1. 0. 3. 1. 3. 3. 2. 2. 2. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 0. 2. 2. 2. 0. 3. 1. 2. 2. 2. 1. 2. 0. 1. 3. 2.\n",
            " 0. 1. 3. 3. 0. 1. 0. 0. 2. 1. 1. 1. 0. 2. 2. 2. 2. 1. 3. 2. 3. 2. 2. 0.\n",
            " 1. 1. 2. 1. 0. 0. 3. 1. 1. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 3. 3. 0. 3. 1. 3. 1. 0. 0. 3. 0. 2. 1. 1. 2. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 0. 1. 1. 2. 3. 3. 1. 3. 2.\n",
            " 2. 2. 3. 1. 3. 3. 1. 3. 1. 3. 3. 2. 2. 0. 2. 0. 1. 2. 1. 3. 2. 2. 3. 3.]\n",
            "[0. 1. 3. 0. 2. 2. 1. 0. 1. 3. 1. 2. 3. 1. 1. 3. 0. 1. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 2. 2. 1. 0. 0. 1. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 3. 1. 1. 0. 1. 2. 2. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 0. 2.\n",
            " 1. 0. 1. 0. 0. 3. 1. 0. 1. 1. 2. 3. 2. 0. 3. 0. 0. 1. 1. 0. 1. 0. 3. 1.\n",
            " 0. 3. 1. 1. 1. 1. 1. 2. 1. 3. 1. 1. 1. 2. 0. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 1. 2. 2. 1. 1. 0. 0. 0. 2. 2. 1. 3. 1. 2. 0. 3. 3. 0.\n",
            " 3. 0. 0. 2. 2. 2. 0. 1. 3. 0. 3. 1. 0. 1. 1. 3. 2. 1. 0. 2. 0. 2. 1. 1.\n",
            " 0. 0. 3. 1. 0. 1. 3. 0. 0. 1. 1. 3. 0. 2. 2. 0. 2. 1. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 2. 2. 2. 0. 1. 0. 1. 0. 0. 3. 3. 2. 2. 1. 1. 2. 0. 0. 1.\n",
            " 2. 0. 1. 3. 3. 1. 1. 3. 2. 3. 1. 3. 0. 3. 1. 0. 3. 3. 0. 1. 1. 1. 2. 1.\n",
            " 1. 2. 3. 3. 2. 0. 3. 3. 0. 0. 1. 2. 3. 3. 1. 0. 2. 2. 3. 3. 1. 0. 2. 0.\n",
            " 1. 3. 0. 0. 1. 2. 2. 2. 3. 2. 3. 2. 3. 0. 1. 3. 1. 0. 2. 3. 0. 1. 1. 1.\n",
            " 0. 0. 0. 0. 2. 2. 1. 2. 3. 1. 2. 1. 2. 3. 2. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 3. 1. 1. 1. 3. 3. 1. 1. 2. 0. 2. 1. 0. 1. 2. 0. 0. 1. 0. 0. 2. 1. 2.\n",
            " 0. 1. 1. 2. 2. 1. 0. 2. 2. 2. 0. 1. 1. 0. 2. 2. 2. 3. 3. 2. 2. 2. 0. 1.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 1. 1. 3. 1. 3. 1. 1. 1. 3.\n",
            " 1. 3. 2. 2. 3. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 2. 2. 0. 1.\n",
            " 1. 3. 0. 2. 1. 3. 0. 0. 2. 1. 1. 3. 1. 1. 3. 2. 1. 0. 1. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 3. 2. 2. 0. 1. 0. 1. 2. 3. 1. 3. 1. 3. 3. 2. 2. 2. 1. 2.\n",
            " 2. 0. 1. 1. 2. 1. 3. 1. 0. 3. 3. 2. 0. 3. 1. 2. 0. 2. 1. 2. 0. 1. 1. 2.\n",
            " 2. 3. 3. 2. 0. 2. 0. 0. 2. 1. 1. 1. 0. 3. 2. 2. 2. 0. 3. 2. 3. 2. 0. 0.\n",
            " 2. 1. 3. 2. 0. 0. 2. 1. 0. 3. 3. 3. 3. 0. 0. 0. 2. 1. 2. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 3. 3. 2. 2. 1. 3. 1. 0. 0. 0. 1. 2. 1. 1. 3. 3. 0. 3. 0. 2. 2.\n",
            " 1. 3. 2. 0. 0. 0. 2. 0. 0. 3. 3. 3. 1. 0. 3. 0. 1. 1. 1. 3. 3. 2. 3. 3.\n",
            " 2. 2. 3. 2. 3. 2. 1. 2. 1. 3. 2. 3. 1. 1. 3. 0. 1. 1. 1. 1. 2. 2. 3. 1.]\n",
            "<class 'list'>\n",
            "final answer =  [0.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 2.0, 3.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0]\n",
            "855     1\n",
            "635     1\n",
            "396     3\n",
            "1816    3\n",
            "1213    1\n",
            "       ..\n",
            "1041    3\n",
            "1799    2\n",
            "1330    2\n",
            "242     3\n",
            "850     3\n",
            "Name: price_range, Length: 600, dtype: int64\n",
            "Accuracy: 0.9833333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample->output(class label)\n",
        "\n",
        "list of samples(vectors)->list of classes-predicted ones\n",
        "\n",
        "actual values->target \n",
        "\n",
        "compare(target,predicted)->accuracy\n",
        "\n",
        "compare the accuracy of 100 trees using random forest and the accuracy of 6 trees formed in the end\n",
        "\n",
        "aprt from accuracy, most seperated distance between two decision trees in each cluster"
      ],
      "metadata": {
        "id": "fzXC7mFilL-B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "SMnACRQnjXhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee97fbc-45ce-4bf5-d64d-f711f0ccf43c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'accuracy': 0.6020000000000001, 'cluster_idx': 0},\n",
              " 1: {'accuracy': 0.6295, 'cluster_idx': 3},\n",
              " 2: {'accuracy': 0.614, 'cluster_idx': 1},\n",
              " 3: {'accuracy': 0.6615, 'cluster_idx': 0},\n",
              " 4: {'accuracy': 0.6295, 'cluster_idx': 1},\n",
              " 5: {'accuracy': 0.6605000000000001, 'cluster_idx': 1},\n",
              " 6: {'accuracy': 0.5815, 'cluster_idx': 2},\n",
              " 7: {'accuracy': 0.6054999999999999, 'cluster_idx': 2},\n",
              " 8: {'accuracy': 0.7554999999999998, 'cluster_idx': 3},\n",
              " 9: {'accuracy': 0.6255000000000001, 'cluster_idx': 2},\n",
              " 10: {'accuracy': 0.6195, 'cluster_idx': 2},\n",
              " 11: {'accuracy': 0.589, 'cluster_idx': 2},\n",
              " 12: {'accuracy': 0.609, 'cluster_idx': 2},\n",
              " 13: {'accuracy': 0.6475000000000001, 'cluster_idx': 2},\n",
              " 14: {'accuracy': 0.6325000000000001, 'cluster_idx': 3},\n",
              " 15: {'accuracy': 0.5795, 'cluster_idx': 2},\n",
              " 16: {'accuracy': 0.6385, 'cluster_idx': 1},\n",
              " 17: {'accuracy': 0.5349999999999999, 'cluster_idx': 2},\n",
              " 18: {'accuracy': 0.6685, 'cluster_idx': 1},\n",
              " 19: {'accuracy': 0.6214999999999999, 'cluster_idx': 0},\n",
              " 20: {'accuracy': 0.5595, 'cluster_idx': 2},\n",
              " 21: {'accuracy': 0.684, 'cluster_idx': 3},\n",
              " 22: {'accuracy': 0.7409999999999999, 'cluster_idx': 3},\n",
              " 23: {'accuracy': 0.6214999999999999, 'cluster_idx': 1},\n",
              " 24: {'accuracy': 0.579, 'cluster_idx': 2},\n",
              " 25: {'accuracy': 0.54, 'cluster_idx': 0},\n",
              " 26: {'accuracy': 0.594, 'cluster_idx': 1},\n",
              " 27: {'accuracy': 0.587, 'cluster_idx': 2},\n",
              " 28: {'accuracy': 0.682, 'cluster_idx': 1},\n",
              " 29: {'accuracy': 0.701, 'cluster_idx': 1},\n",
              " 30: {'accuracy': 0.6655, 'cluster_idx': 1},\n",
              " 31: {'accuracy': 0.61, 'cluster_idx': 2},\n",
              " 32: {'accuracy': 0.7749999999999999, 'cluster_idx': 3},\n",
              " 33: {'accuracy': 0.6005, 'cluster_idx': 1},\n",
              " 34: {'accuracy': 0.7055, 'cluster_idx': 2},\n",
              " 35: {'accuracy': 0.7314999999999999, 'cluster_idx': 3},\n",
              " 36: {'accuracy': 0.6175, 'cluster_idx': 2},\n",
              " 37: {'accuracy': 0.737, 'cluster_idx': 1},\n",
              " 38: {'accuracy': 0.621, 'cluster_idx': 1},\n",
              " 39: {'accuracy': 0.6629999999999999, 'cluster_idx': 3},\n",
              " 40: {'accuracy': 0.5505, 'cluster_idx': 0},\n",
              " 41: {'accuracy': 0.643, 'cluster_idx': 2},\n",
              " 42: {'accuracy': 0.7285000000000001, 'cluster_idx': 3},\n",
              " 43: {'accuracy': 0.5525, 'cluster_idx': 2},\n",
              " 44: {'accuracy': 0.6075000000000002, 'cluster_idx': 2},\n",
              " 45: {'accuracy': 0.626, 'cluster_idx': 1},\n",
              " 46: {'accuracy': 0.624, 'cluster_idx': 1},\n",
              " 47: {'accuracy': 0.575, 'cluster_idx': 0},\n",
              " 48: {'accuracy': 0.6100000000000001, 'cluster_idx': 2},\n",
              " 49: {'accuracy': 0.5904999999999999, 'cluster_idx': 0},\n",
              " 50: {'accuracy': 0.609, 'cluster_idx': 1},\n",
              " 51: {'accuracy': 0.64, 'cluster_idx': 3},\n",
              " 52: {'accuracy': 0.568, 'cluster_idx': 0},\n",
              " 53: {'accuracy': 0.5595000000000001, 'cluster_idx': 0},\n",
              " 54: {'accuracy': 0.6715000000000001, 'cluster_idx': 1},\n",
              " 55: {'accuracy': 0.6545, 'cluster_idx': 1},\n",
              " 56: {'accuracy': 0.6519999999999999, 'cluster_idx': 1},\n",
              " 57: {'accuracy': 0.5820000000000001, 'cluster_idx': 0},\n",
              " 58: {'accuracy': 0.6315000000000001, 'cluster_idx': 1},\n",
              " 59: {'accuracy': 0.6845, 'cluster_idx': 3},\n",
              " 60: {'accuracy': 0.6045, 'cluster_idx': 1},\n",
              " 61: {'accuracy': 0.6380000000000001, 'cluster_idx': 1},\n",
              " 62: {'accuracy': 0.634, 'cluster_idx': 1},\n",
              " 63: {'accuracy': 0.7, 'cluster_idx': 1},\n",
              " 64: {'accuracy': 0.7195, 'cluster_idx': 1},\n",
              " 65: {'accuracy': 0.6105, 'cluster_idx': 1},\n",
              " 66: {'accuracy': 0.5650000000000001, 'cluster_idx': 2},\n",
              " 67: {'accuracy': 0.7314999999999999, 'cluster_idx': 3},\n",
              " 68: {'accuracy': 0.7075, 'cluster_idx': 3},\n",
              " 69: {'accuracy': 0.559, 'cluster_idx': 1},\n",
              " 70: {'accuracy': 0.5425000000000001, 'cluster_idx': 1},\n",
              " 71: {'accuracy': 0.6135, 'cluster_idx': 1},\n",
              " 72: {'accuracy': 0.7455, 'cluster_idx': 3},\n",
              " 73: {'accuracy': 0.573, 'cluster_idx': 2},\n",
              " 74: {'accuracy': 0.735, 'cluster_idx': 3},\n",
              " 75: {'accuracy': 0.6599999999999999, 'cluster_idx': 3},\n",
              " 76: {'accuracy': 0.5864999999999999, 'cluster_idx': 0},\n",
              " 77: {'accuracy': 0.5565, 'cluster_idx': 2},\n",
              " 78: {'accuracy': 0.516, 'cluster_idx': 0},\n",
              " 79: {'accuracy': 0.5495000000000001, 'cluster_idx': 0},\n",
              " 80: {'accuracy': 0.687, 'cluster_idx': 2},\n",
              " 81: {'accuracy': 0.6935, 'cluster_idx': 1},\n",
              " 82: {'accuracy': 0.6565000000000001, 'cluster_idx': 2},\n",
              " 83: {'accuracy': 0.5589999999999999, 'cluster_idx': 1},\n",
              " 84: {'accuracy': 0.5945, 'cluster_idx': 1},\n",
              " 85: {'accuracy': 0.6305, 'cluster_idx': 0},\n",
              " 86: {'accuracy': 0.603, 'cluster_idx': 1},\n",
              " 87: {'accuracy': 0.56, 'cluster_idx': 2},\n",
              " 88: {'accuracy': 0.568, 'cluster_idx': 2},\n",
              " 89: {'accuracy': 0.5745, 'cluster_idx': 0},\n",
              " 90: {'accuracy': 0.6950000000000001, 'cluster_idx': 1},\n",
              " 91: {'accuracy': 0.587, 'cluster_idx': 0},\n",
              " 92: {'accuracy': 0.5810000000000001, 'cluster_idx': 2},\n",
              " 93: {'accuracy': 0.6085, 'cluster_idx': 2},\n",
              " 94: {'accuracy': 0.721, 'cluster_idx': 3},\n",
              " 95: {'accuracy': 0.7295, 'cluster_idx': 2},\n",
              " 96: {'accuracy': 0.7375, 'cluster_idx': 3},\n",
              " 97: {'accuracy': 0.635, 'cluster_idx': 0},\n",
              " 98: {'accuracy': 0.593, 'cluster_idx': 1},\n",
              " 99: {'accuracy': 0.6205, 'cluster_idx': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "prf2.info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#agglo\n",
        "getMaxAccuracyCluster(prf2.info)"
      ],
      "metadata": {
        "id": "jhUn1XQrixZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea8b9f0-4df4-4fa7-837d-9fb4fe1cd833"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': [3], '3': [32], '1': [37], '2': [95]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'0': 3}\n",
            "{'3': 32}\n",
            "{'1': 37}\n",
            "{'2': 95}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': [3], '1': [37], '2': [95], '3': [32]}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf2.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf2)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "print(y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfW-cEyypXHa",
        "outputId": "f14501e2-8b65-4890-95a1-7a0fdb5186c4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': [3], '3': [32], '1': [37], '2': [95]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'0': 3}\n",
            "{'3': 32}\n",
            "{'1': 37}\n",
            "{'2': 95}\n",
            "[1. 1. 2. 2. 1. 2. 1. 0. 1. 3. 1. 2. 2. 0. 0. 3. 0. 1. 0. 2. 0. 0. 3. 1.\n",
            " 3. 3. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 2. 2. 1. 0. 1. 1. 0. 0. 2. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 2. 1. 3. 3. 2. 2. 1. 2. 0. 2. 3. 0. 1. 2. 0. 2.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 3. 1. 0. 2. 0. 0. 1. 3. 0. 0. 2. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 1. 0. 1. 0. 3. 2. 3. 2. 2. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 1. 2. 1. 1. 0. 1. 0. 3. 2. 1. 3. 2. 2. 0. 2. 3. 0.\n",
            " 1. 0. 2. 2. 2. 2. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 3. 1. 1. 2. 3. 0. 2. 3.\n",
            " 3. 0. 2. 2. 0. 1. 3. 0. 2. 1. 0. 3. 0. 1. 2. 0. 2. 1. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 2. 1. 1. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 2. 2. 1. 1. 1. 0. 0.\n",
            " 2. 0. 1. 3. 2. 1. 1. 3. 3. 3. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 2. 1. 0. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 2. 3. 1. 0. 3. 3. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 1. 2. 1. 1. 3. 1. 1. 1. 3. 3. 3. 2. 0. 3. 2. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 1. 0. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 1. 2. 1. 2.\n",
            " 1. 1. 3. 2. 2. 1. 2. 1. 2. 3. 0. 1. 1. 0. 0. 2. 2. 2. 3. 0. 2. 0. 1. 1.\n",
            " 3. 2. 2. 1. 3. 3. 0. 1. 3. 0. 2. 2. 2. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 2.\n",
            " 0. 2. 2. 2. 2. 2. 2. 1. 2. 1. 3. 0. 0. 0. 0. 2. 0. 2. 2. 3. 2. 1. 0. 1.\n",
            " 1. 0. 1. 1. 2. 3. 0. 0. 2. 1. 1. 3. 1. 1. 0. 2. 1. 0. 1. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 3. 1. 0. 1. 1. 1. 1. 1. 0. 3. 1. 3. 3. 0. 2. 1. 2. 2.\n",
            " 1. 1. 0. 1. 2. 1. 0. 2. 0. 2. 3. 3. 0. 3. 1. 2. 2. 2. 1. 1. 0. 1. 2. 2.\n",
            " 1. 2. 3. 2. 1. 1. 0. 0. 2. 1. 1. 1. 1. 3. 2. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 2. 1. 2. 2. 0. 0. 3. 2. 1. 3. 3. 1. 3. 0. 0. 0. 2. 3. 1. 0. 2. 1. 3. 0.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 1. 1. 3. 3. 1. 0. 3. 3. 1. 3. 1. 0. 3. 0. 1. 2. 1. 3. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 2. 2. 2. 2. 1. 3. 2. 3. 1. 2. 2. 0. 1. 1. 1. 3. 2. 2. 3. 3.]\n",
            "[0. 1. 3. 3. 1. 2. 1. 0. 1. 2. 1. 2. 2. 0. 1. 2. 0. 1. 0. 2. 0. 0. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 2. 2. 1. 0. 0. 1. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 2. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 2. 0. 0. 1. 2. 3. 1. 0. 3. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 0. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 2. 1. 1. 1. 0. 0. 0. 2. 2. 1. 3. 2. 2. 0. 2. 3. 0.\n",
            " 1. 0. 0. 2. 2. 2. 0. 3. 2. 3. 3. 0. 3. 0. 1. 1. 3. 1. 0. 3. 3. 0. 2. 3.\n",
            " 3. 0. 2. 1. 0. 1. 3. 0. 2. 3. 0. 3. 0. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 2. 3. 0. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 2. 2. 1. 1. 3. 3. 3. 2. 3. 0. 3. 1. 3. 0. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 1. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 1. 3. 1. 0. 3. 3. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 2. 1. 2. 3. 1. 1. 0. 2. 3. 3. 2. 0. 2. 0. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 3. 1. 2.\n",
            " 0. 1. 3. 2. 2. 1. 0. 2. 2. 2. 0. 1. 1. 0. 3. 2. 2. 3. 3. 2. 2. 2. 1. 2.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 0. 1. 3. 1. 3. 1. 2. 0. 2.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 3. 1. 0. 1.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 3. 0. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 0. 1. 1. 1. 2. 1. 1. 3. 1. 3. 3. 2. 2. 2. 1. 2.\n",
            " 2. 0. 1. 1. 1. 0. 0. 1. 0. 2. 3. 2. 0. 3. 1. 2. 3. 2. 1. 2. 0. 1. 2. 2.\n",
            " 1. 2. 3. 2. 2. 1. 1. 0. 2. 1. 1. 0. 0. 3. 2. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 2. 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 1. 2. 1. 3. 1.\n",
            " 3. 1. 3. 3. 3. 2. 3. 1. 3. 1. 0. 0. 2. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 2.\n",
            " 1. 3. 2. 0. 1. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 0. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 1. 2. 3. 1. 3. 2. 2. 2. 1. 2. 2. 3. 1. 2. 2. 0. 1. 2. 0. 3. 2. 3. 3. 3.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 1. 1. 0. 2. 0. 1. 2. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 2. 2. 1. 0. 1. 2. 0. 0. 0. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 2. 0. 2. 3. 2. 1.\n",
            " 2. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 3. 1. 0. 3. 1. 0. 1. 1. 0. 0. 2. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 0. 3. 1. 0. 1. 2. 0. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 2. 2. 1. 1. 0. 1. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 0. 0. 0. 2. 2. 2. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 3. 1. 0. 2. 3. 0. 2. 3.\n",
            " 2. 0. 1. 1. 0. 1. 3. 0. 2. 2. 1. 3. 0. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 2.\n",
            " 2. 2. 3. 3. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 1. 0. 1. 3. 3. 1. 1. 3. 3. 3. 2. 3. 0. 3. 1. 3. 1. 3. 0. 3. 1. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 1.\n",
            " 3. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 2. 3. 1. 0. 3. 3. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 2. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 1. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 2. 1. 2.\n",
            " 0. 2. 3. 2. 2. 1. 0. 2. 2. 2. 1. 1. 1. 1. 2. 2. 2. 3. 3. 1. 2. 1. 0. 1.\n",
            " 2. 1. 2. 1. 3. 1. 0. 0. 3. 0. 2. 2. 2. 0. 1. 1. 2. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 3. 0. 2. 2. 0. 2. 2. 0. 0.\n",
            " 1. 3. 1. 1. 1. 3. 0. 1. 2. 1. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 2. 1. 1. 2. 1. 0. 0. 1. 1. 2. 1. 1. 3. 1. 3. 2. 2. 2. 3. 1. 3.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 0. 2. 3. 2. 0. 3. 2. 2. 2. 2. 1. 2. 0. 1. 2. 2.\n",
            " 1. 1. 3. 2. 1. 1. 1. 0. 2. 1. 1. 1. 0. 3. 2. 2. 2. 0. 3. 2. 3. 1. 2. 1.\n",
            " 2. 1. 2. 2. 0. 0. 2. 1. 1. 3. 3. 3. 3. 0. 0. 1. 1. 3. 0. 0. 2. 1. 3. 2.\n",
            " 2. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 2. 1. 2. 3. 3. 1. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 2. 3. 1. 0. 3. 1. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 1. 2. 3. 1. 3. 2. 2. 3. 0. 3. 2. 3. 2. 1. 2. 1. 1. 1. 1. 3. 2. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 3. 1. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 0. 1. 0. 2. 0. 0. 3. 1.\n",
            " 3. 2. 2. 0. 1. 3. 1. 2. 0. 1. 1. 0. 2. 2. 2. 0. 0. 1. 0. 0. 1. 0. 1. 2.\n",
            " 3. 3. 3. 2. 0. 3. 0. 1. 2. 2. 3. 3. 0. 0. 2. 2. 0. 2. 3. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 3. 1. 0. 3. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 0. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 0. 0. 1. 0. 1. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 2. 2. 2. 1. 1. 0. 0. 0. 2. 2. 3. 2. 3. 3. 1. 3. 3. 0.\n",
            " 1. 0. 0. 2. 2. 2. 0. 3. 2. 3. 3. 1. 3. 0. 0. 1. 3. 1. 0. 2. 2. 0. 1. 3.\n",
            " 3. 0. 2. 1. 0. 0. 3. 0. 2. 3. 0. 3. 0. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 2. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 1. 1. 2. 2. 1. 1. 3. 3. 3. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 3. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 3. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 1. 2. 2. 2. 3. 2. 3. 0. 2. 3. 0. 0. 3. 3. 1. 1. 1. 1.\n",
            " 1. 0. 0. 1. 2. 2. 2. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 1. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 2. 2. 1. 2. 1. 0. 1. 0. 0. 0. 3. 0. 0. 2. 2. 2.\n",
            " 0. 1. 3. 1. 2. 1. 0. 1. 3. 2. 0. 1. 1. 0. 2. 2. 3. 3. 3. 1. 2. 2. 1. 1.\n",
            " 2. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 3. 1. 1. 1. 0. 1. 3. 1. 3. 1. 3. 1. 3.\n",
            " 3. 3. 2. 2. 2. 2. 3. 1. 2. 1. 3. 0. 0. 0. 1. 3. 0. 2. 1. 0. 2. 2. 0. 0.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 2. 1. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 2. 1. 3. 0. 1. 1. 2. 1. 0. 1. 1. 1. 2. 1. 1. 1. 1. 3. 1. 2. 2. 2. 1. 3.\n",
            " 1. 0. 3. 1. 1. 1. 0. 1. 0. 2. 3. 2. 0. 3. 2. 3. 2. 2. 1. 2. 0. 1. 2. 2.\n",
            " 1. 1. 3. 2. 2. 1. 0. 0. 2. 1. 1. 1. 0. 3. 1. 2. 2. 0. 3. 2. 3. 2. 1. 0.\n",
            " 2. 1. 2. 2. 0. 0. 3. 1. 1. 3. 2. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 2. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 2. 2. 3. 3. 0. 0. 3. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 2. 0. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 3. 1. 3. 2. 1. 2. 2. 3. 3. 1. 2. 1. 1. 1. 0. 2. 2. 2. 3. 3.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 2.0, 3.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0]\n",
            "855     1\n",
            "635     1\n",
            "396     3\n",
            "1816    3\n",
            "1213    1\n",
            "       ..\n",
            "1041    3\n",
            "1799    2\n",
            "1330    2\n",
            "242     3\n",
            "850     3\n",
            "Name: price_range, Length: 600, dtype: int64\n",
            "Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OeWPHBJSjZND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea14eee3-7a9f-4bcf-966c-0506c94aaf58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'accuracy': 0.7135, 'cluster_idx': 4},\n",
              " 1: {'accuracy': 0.603, 'cluster_idx': 1},\n",
              " 2: {'accuracy': 0.591, 'cluster_idx': 3},\n",
              " 3: {'accuracy': 0.7115, 'cluster_idx': 0},\n",
              " 4: {'accuracy': 0.5615, 'cluster_idx': 0},\n",
              " 5: {'accuracy': 0.5675000000000001, 'cluster_idx': 2},\n",
              " 6: {'accuracy': 0.5735, 'cluster_idx': 3},\n",
              " 7: {'accuracy': 0.677, 'cluster_idx': 0},\n",
              " 8: {'accuracy': 0.6105, 'cluster_idx': 4},\n",
              " 9: {'accuracy': 0.6655, 'cluster_idx': 4},\n",
              " 10: {'accuracy': 0.7195, 'cluster_idx': 1},\n",
              " 11: {'accuracy': 0.5930000000000001, 'cluster_idx': 2},\n",
              " 12: {'accuracy': 0.5855, 'cluster_idx': 2},\n",
              " 13: {'accuracy': 0.6759999999999999, 'cluster_idx': 2},\n",
              " 14: {'accuracy': 0.6125, 'cluster_idx': 4},\n",
              " 15: {'accuracy': 0.6855, 'cluster_idx': 2},\n",
              " 16: {'accuracy': 0.6685, 'cluster_idx': 4},\n",
              " 17: {'accuracy': 0.744, 'cluster_idx': 2},\n",
              " 18: {'accuracy': 0.5700000000000001, 'cluster_idx': 4},\n",
              " 19: {'accuracy': 0.528, 'cluster_idx': 3},\n",
              " 20: {'accuracy': 0.5539999999999999, 'cluster_idx': 3},\n",
              " 21: {'accuracy': 0.552, 'cluster_idx': 3},\n",
              " 22: {'accuracy': 0.6555, 'cluster_idx': 2},\n",
              " 23: {'accuracy': 0.615, 'cluster_idx': 4},\n",
              " 24: {'accuracy': 0.726, 'cluster_idx': 2},\n",
              " 25: {'accuracy': 0.533, 'cluster_idx': 1},\n",
              " 26: {'accuracy': 0.6515000000000001, 'cluster_idx': 0},\n",
              " 27: {'accuracy': 0.55, 'cluster_idx': 3},\n",
              " 28: {'accuracy': 0.6315000000000002, 'cluster_idx': 4},\n",
              " 29: {'accuracy': 0.603, 'cluster_idx': 4},\n",
              " 30: {'accuracy': 0.697, 'cluster_idx': 0},\n",
              " 31: {'accuracy': 0.6174999999999999, 'cluster_idx': 4},\n",
              " 32: {'accuracy': 0.5539999999999999, 'cluster_idx': 0},\n",
              " 33: {'accuracy': 0.536, 'cluster_idx': 3},\n",
              " 34: {'accuracy': 0.557, 'cluster_idx': 1},\n",
              " 35: {'accuracy': 0.6425000000000001, 'cluster_idx': 3},\n",
              " 36: {'accuracy': 0.639, 'cluster_idx': 2},\n",
              " 37: {'accuracy': 0.659, 'cluster_idx': 0},\n",
              " 38: {'accuracy': 0.5595000000000001, 'cluster_idx': 1},\n",
              " 39: {'accuracy': 0.622, 'cluster_idx': 0},\n",
              " 40: {'accuracy': 0.5660000000000001, 'cluster_idx': 0},\n",
              " 41: {'accuracy': 0.7575000000000001, 'cluster_idx': 2},\n",
              " 42: {'accuracy': 0.5825, 'cluster_idx': 4},\n",
              " 43: {'accuracy': 0.613, 'cluster_idx': 1},\n",
              " 44: {'accuracy': 0.579, 'cluster_idx': 1},\n",
              " 45: {'accuracy': 0.6425, 'cluster_idx': 3},\n",
              " 46: {'accuracy': 0.615, 'cluster_idx': 3},\n",
              " 47: {'accuracy': 0.6530000000000001, 'cluster_idx': 4},\n",
              " 48: {'accuracy': 0.6235, 'cluster_idx': 4},\n",
              " 49: {'accuracy': 0.7435, 'cluster_idx': 2},\n",
              " 50: {'accuracy': 0.5685, 'cluster_idx': 3},\n",
              " 51: {'accuracy': 0.709, 'cluster_idx': 2},\n",
              " 52: {'accuracy': 0.5725, 'cluster_idx': 0},\n",
              " 53: {'accuracy': 0.603, 'cluster_idx': 3},\n",
              " 54: {'accuracy': 0.6180000000000001, 'cluster_idx': 1},\n",
              " 55: {'accuracy': 0.668, 'cluster_idx': 0},\n",
              " 56: {'accuracy': 0.6449999999999999, 'cluster_idx': 0},\n",
              " 57: {'accuracy': 0.6154999999999999, 'cluster_idx': 1},\n",
              " 58: {'accuracy': 0.641, 'cluster_idx': 4},\n",
              " 59: {'accuracy': 0.6504999999999999, 'cluster_idx': 4},\n",
              " 60: {'accuracy': 0.6920000000000001, 'cluster_idx': 0},\n",
              " 61: {'accuracy': 0.7034999999999999, 'cluster_idx': 0},\n",
              " 62: {'accuracy': 0.6195, 'cluster_idx': 0},\n",
              " 63: {'accuracy': 0.6795, 'cluster_idx': 2},\n",
              " 64: {'accuracy': 0.5745, 'cluster_idx': 4},\n",
              " 65: {'accuracy': 0.579, 'cluster_idx': 1},\n",
              " 66: {'accuracy': 0.5755000000000001, 'cluster_idx': 1},\n",
              " 67: {'accuracy': 0.5965, 'cluster_idx': 3},\n",
              " 68: {'accuracy': 0.687, 'cluster_idx': 2},\n",
              " 69: {'accuracy': 0.693, 'cluster_idx': 0},\n",
              " 70: {'accuracy': 0.6245, 'cluster_idx': 3},\n",
              " 71: {'accuracy': 0.601, 'cluster_idx': 3},\n",
              " 72: {'accuracy': 0.719, 'cluster_idx': 0},\n",
              " 73: {'accuracy': 0.7235, 'cluster_idx': 2},\n",
              " 74: {'accuracy': 0.7275, 'cluster_idx': 0},\n",
              " 75: {'accuracy': 0.5955, 'cluster_idx': 4},\n",
              " 76: {'accuracy': 0.579, 'cluster_idx': 0},\n",
              " 77: {'accuracy': 0.579, 'cluster_idx': 1},\n",
              " 78: {'accuracy': 0.6115, 'cluster_idx': 0},\n",
              " 79: {'accuracy': 0.5519999999999999, 'cluster_idx': 3},\n",
              " 80: {'accuracy': 0.6745, 'cluster_idx': 4},\n",
              " 81: {'accuracy': 0.5854999999999999, 'cluster_idx': 4},\n",
              " 82: {'accuracy': 0.582, 'cluster_idx': 1},\n",
              " 83: {'accuracy': 0.5805, 'cluster_idx': 3},\n",
              " 84: {'accuracy': 0.5329999999999999, 'cluster_idx': 3},\n",
              " 85: {'accuracy': 0.595, 'cluster_idx': 1},\n",
              " 86: {'accuracy': 0.548, 'cluster_idx': 4},\n",
              " 87: {'accuracy': 0.7625, 'cluster_idx': 2},\n",
              " 88: {'accuracy': 0.5615, 'cluster_idx': 2},\n",
              " 89: {'accuracy': 0.7344999999999999, 'cluster_idx': 4},\n",
              " 90: {'accuracy': 0.6659999999999999, 'cluster_idx': 4},\n",
              " 91: {'accuracy': 0.6715, 'cluster_idx': 2},\n",
              " 92: {'accuracy': 0.57, 'cluster_idx': 0},\n",
              " 93: {'accuracy': 0.5984999999999999, 'cluster_idx': 4},\n",
              " 94: {'accuracy': 0.616, 'cluster_idx': 3},\n",
              " 95: {'accuracy': 0.7165, 'cluster_idx': 0},\n",
              " 96: {'accuracy': 0.6315, 'cluster_idx': 4},\n",
              " 97: {'accuracy': 0.6515000000000001, 'cluster_idx': 3},\n",
              " 98: {'accuracy': 0.6305000000000001, 'cluster_idx': 0},\n",
              " 99: {'accuracy': 0.5845, 'cluster_idx': 2}}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "prf3.info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gaussian\n",
        "getMaxAccuracyCluster(prf3.info)"
      ],
      "metadata": {
        "id": "CS_NFfLxjuka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbb2f0c-85be-4fab-889c-5e54d03062d9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4': [89], '1': [10], '3': [97], '0': [74], '2': [87]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'4': 89}\n",
            "{'1': 10}\n",
            "{'3': 97}\n",
            "{'0': 74}\n",
            "{'2': 87}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': [74], '1': [10], '2': [87], '3': [97], '4': [89]}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf3.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf3)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "print(y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwdUtiQNpfoi",
        "outputId": "8386c771-4528-4188-f998-ef8f7ff4f145"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4': [89], '1': [10], '3': [97], '0': [74], '2': [87]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'4': 89}\n",
            "{'1': 10}\n",
            "{'3': 97}\n",
            "{'0': 74}\n",
            "{'2': 87}\n",
            "[1. 1. 3. 3. 0. 2. 1. 0. 0. 2. 1. 2. 2. 0. 1. 3. 0. 0. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 2. 1. 0. 1. 1. 0. 2. 2. 1. 0. 0. 1. 1. 0. 0. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 3. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 2. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 1. 3. 0. 0. 3. 0. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 0. 0. 1. 0. 3. 3. 3. 3. 3. 3.\n",
            " 2. 0. 0. 3. 3. 1. 3. 2. 1. 3. 0. 0. 1. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 1. 2. 2. 2. 0. 3. 2. 3. 2. 1. 2. 0. 1. 1. 3. 1. 0. 2. 3. 0. 3. 3.\n",
            " 3. 0. 2. 1. 0. 1. 3. 0. 1. 3. 0. 3. 0. 1. 2. 0. 3. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 2. 3. 0. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 1. 1. 1. 3. 2. 1. 2. 3. 3. 2. 1. 3. 0. 2. 1. 3. 1. 3. 0. 3. 2. 1. 2. 1.\n",
            " 0. 0. 3. 3. 3. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 2. 1. 3. 0. 3. 1. 1. 1. 1.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 2. 3. 1. 1. 3. 3. 0. 1. 1. 1.\n",
            " 1. 0. 0. 0. 2. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 1. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 2. 1. 3.\n",
            " 0. 1. 3. 2. 2. 1. 0. 1. 3. 2. 0. 1. 1. 0. 2. 3. 2. 3. 3. 1. 3. 2. 1. 1.\n",
            " 3. 0. 2. 1. 3. 0. 0. 0. 2. 0. 2. 3. 2. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 1. 1. 2. 3. 1. 2. 1. 3. 0. 1. 0. 1. 3. 0. 2. 2. 0. 1. 2. 0. 1.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 2. 0. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 3. 1. 3. 3. 2. 2. 2. 1. 2.\n",
            " 2. 2. 1. 1. 1. 1. 0. 1. 0. 2. 2. 1. 0. 3. 1. 2. 2. 1. 1. 2. 0. 1. 2. 2.\n",
            " 1. 1. 2. 2. 1. 1. 0. 0. 3. 1. 1. 0. 0. 3. 2. 2. 2. 0. 3. 2. 2. 2. 2. 0.\n",
            " 2. 1. 2. 2. 1. 0. 3. 1. 2. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 2. 0. 2. 1. 1. 3. 3. 1. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 0. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 0. 2. 3. 1. 3. 2. 2. 2. 1. 3. 2. 3. 1. 1. 2. 0. 1. 2. 1. 2. 1. 2. 3. 3.]\n",
            "[1. 3. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 3. 3. 0. 1. 0. 3. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 2. 2. 1. 1. 0. 2. 2. 1. 0. 0. 2. 3. 0. 1. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 1. 3. 0. 1. 3. 1. 1.\n",
            " 0. 1. 0. 0. 0. 0. 1. 0. 0. 2. 2. 3. 1. 0. 3. 0. 0. 1. 2. 2. 0. 0. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 1. 3. 1. 1. 1. 2. 1. 0. 1. 0. 2. 3. 3. 1. 3. 3.\n",
            " 2. 0. 0. 1. 3. 0. 3. 1. 2. 1. 1. 0. 0. 0. 3. 3. 0. 3. 2. 3. 0. 3. 3. 0.\n",
            " 0. 0. 2. 2. 2. 2. 0. 3. 1. 3. 3. 1. 3. 0. 1. 1. 3. 2. 0. 2. 3. 0. 2. 3.\n",
            " 3. 0. 2. 3. 0. 1. 3. 0. 2. 3. 0. 3. 3. 1. 2. 0. 2. 0. 0. 0. 2. 3. 2. 1.\n",
            " 2. 1. 3. 2. 3. 1. 2. 2. 0. 2. 0. 1. 1. 2. 3. 3. 3. 3. 3. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 1. 0. 3. 3. 3. 1. 3. 1. 3. 1. 3. 1. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 1. 0. 3. 3. 0. 3. 0. 0. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 1. 1. 0. 2. 3. 3. 1. 2. 2. 2. 3. 2. 3. 1. 2. 3. 1. 0. 3. 3. 0. 1. 1. 1.\n",
            " 2. 0. 0. 0. 3. 2. 1. 1. 3. 0. 1. 1. 1. 3. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 1. 0. 1. 1. 3. 3. 1. 1. 1. 3. 1. 1. 0. 1. 0. 0. 0. 2. 0. 0. 2. 1. 0.\n",
            " 0. 0. 3. 2. 2. 1. 2. 2. 2. 2. 0. 0. 1. 0. 2. 2. 2. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 2. 3. 0. 0. 0. 3. 2. 2. 3. 2. 0. 3. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 0. 2. 1. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 2. 2. 0. 0.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 2. 1. 1. 3. 1. 2. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 2. 1. 1. 3. 1. 0. 1. 1. 0. 0. 1. 2. 3. 1. 0. 3. 2. 2. 0. 1. 2.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 0. 2. 3. 2. 1. 3. 1. 2. 2. 1. 1. 2. 0. 1. 2. 2.\n",
            " 1. 1. 3. 2. 0. 1. 0. 0. 2. 2. 1. 0. 0. 3. 2. 2. 2. 0. 3. 2. 3. 2. 0. 0.\n",
            " 3. 1. 2. 2. 0. 0. 3. 1. 1. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 2. 1. 3. 2. 3. 1. 3. 2. 3. 1. 0. 0. 3. 0. 1. 1. 1. 3. 3. 0. 3. 1. 2. 3.\n",
            " 1. 1. 0. 1. 1. 3. 2. 0. 3. 3. 3. 3. 1. 1. 3. 0. 1. 1. 1. 2. 3. 1. 3. 3.\n",
            " 3. 2. 3. 1. 3. 3. 2. 2. 0. 3. 2. 3. 0. 1. 1. 0. 1. 1. 1. 3. 2. 2. 3. 1.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 2. 2. 2. 1. 1. 3. 0. 1. 0. 3. 0. 0. 3. 1.\n",
            " 3. 1. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 3. 0.\n",
            " 3. 3. 3. 2. 0. 2. 0. 2. 3. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 3. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 1. 2. 2. 3. 2. 0. 3. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 2. 0. 3. 1. 0. 1. 2. 0. 0. 1. 0. 3. 1. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 2. 2. 1. 1. 0. 0. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 2. 0. 0. 2. 2. 2. 0. 2. 3. 3. 0. 1. 1. 0. 0. 1. 3. 1. 0. 2. 2. 1. 2. 3.\n",
            " 3. 0. 2. 2. 0. 1. 3. 0. 2. 3. 0. 3. 0. 2. 2. 0. 2. 2. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 1. 1. 2. 2. 2. 2. 0. 2. 0. 0. 2. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 2. 1. 0. 2. 1. 1. 3. 3. 3. 1. 3. 0. 3. 2. 2. 0. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 1. 0. 3. 2. 0. 1. 0. 2. 0. 0. 3. 1. 1. 1. 0.\n",
            " 0. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 1. 3. 1. 3. 3. 3. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 2. 1. 1. 2. 3. 1. 1. 1. 2. 3. 3. 3. 0. 3. 0. 1. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 2. 1. 1. 1. 1. 2. 0. 0. 1. 0. 0. 0. 2. 0. 0. 3. 2. 2.\n",
            " 0. 2. 3. 2. 2. 1. 1. 2. 3. 2. 0. 1. 2. 0. 2. 2. 2. 2. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 0. 3. 3. 0. 2. 1. 1. 3. 1. 3. 1. 2. 0. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 2. 2. 1. 3. 0. 0. 0. 2. 2. 0. 2. 2. 0. 1. 1. 0. 0.\n",
            " 1. 3. 3. 0. 1. 3. 0. 0. 2. 1. 1. 3. 1. 1. 2. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 1. 1. 3. 1. 1. 1. 2. 0. 0. 1. 1. 1. 2. 1. 1. 3. 1. 3. 2. 3. 2. 1. 1. 2.\n",
            " 1. 0. 1. 3. 2. 0. 0. 2. 0. 2. 3. 2. 0. 3. 1. 2. 2. 2. 1. 2. 0. 1. 2. 2.\n",
            " 1. 2. 3. 2. 0. 2. 1. 0. 1. 1. 1. 1. 0. 2. 2. 2. 1. 0. 3. 2. 1. 2. 2. 0.\n",
            " 2. 1. 2. 2. 0. 0. 2. 1. 1. 3. 3. 1. 3. 0. 0. 1. 2. 3. 0. 0. 3. 1. 3. 2.\n",
            " 3. 1. 3. 2. 2. 0. 3. 1. 1. 1. 0. 0. 3. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 2. 0. 3. 3. 3. 3. 3. 0. 2. 0. 1. 1. 2. 2. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 3. 2. 2. 2. 1. 3. 2. 3. 2. 1. 2. 2. 1. 2. 1. 3. 2. 3. 3. 3.]\n",
            "[1. 1. 1. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 0. 3. 0. 1. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 2. 1. 1. 0. 0. 0. 2. 2. 1. 1. 0. 1. 0. 0. 0. 0. 2. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 1. 2. 1. 3. 3. 0. 1. 3. 2. 0. 2. 3. 0. 0. 3. 0. 1.\n",
            " 2. 0. 0. 0. 2. 0. 1. 1. 0. 1. 2. 2. 1. 0. 3. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 2. 0. 1. 1. 1. 1. 1. 1. 3. 1. 1. 1. 3. 0. 0. 1. 0. 2. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 2. 2. 1. 1. 0. 0. 0. 2. 2. 0. 3. 2. 3. 0. 2. 3. 1.\n",
            " 1. 0. 1. 2. 2. 2. 0. 3. 3. 3. 3. 1. 3. 0. 1. 2. 3. 1. 0. 2. 2. 0. 2. 3.\n",
            " 2. 0. 2. 1. 0. 0. 3. 0. 2. 3. 1. 3. 0. 2. 2. 0. 2. 0. 0. 0. 2. 3. 0. 0.\n",
            " 2. 2. 3. 2. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 1. 1. 3. 2. 1. 2. 3. 0. 3. 1. 3. 0. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 1. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 2. 2. 3. 2. 3. 0. 2. 3. 1. 0. 3. 3. 0. 0. 1. 1.\n",
            " 2. 0. 1. 0. 2. 2. 2. 2. 3. 1. 1. 1. 2. 2. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 0. 1. 1. 2. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 1. 1. 2.\n",
            " 0. 1. 3. 2. 2. 1. 0. 2. 2. 1. 0. 0. 1. 0. 2. 2. 3. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 0. 2. 0. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 1. 1. 2. 2. 3. 0. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 2. 2. 0. 1.\n",
            " 1. 3. 1. 1. 0. 3. 1. 0. 2. 1. 1. 3. 1. 0. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 0. 2. 1. 1. 1. 1. 1. 3. 1. 3. 3. 2. 2. 1. 1. 2.\n",
            " 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 2. 0. 3. 1. 2. 2. 2. 1. 3. 1. 1. 2. 2.\n",
            " 1. 1. 3. 2. 1. 1. 0. 0. 2. 1. 2. 0. 0. 3. 2. 2. 2. 0. 3. 2. 3. 1. 2. 0.\n",
            " 2. 1. 2. 3. 0. 0. 3. 1. 0. 3. 3. 3. 3. 0. 0. 0. 1. 3. 1. 1. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 3. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 1. 0. 0. 3. 1. 1. 3. 3. 3. 3. 1. 0. 2. 0. 1. 1. 1. 3. 3. 2. 3. 2.\n",
            " 2. 2. 3. 1. 3. 1. 2. 2. 1. 3. 2. 3. 1. 1. 2. 0. 1. 1. 1. 2. 2. 2. 3. 3.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 0. 1. 0. 3. 0. 0. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 2. 0. 1. 0. 0. 2. 2. 1. 0. 0. 1. 0. 0. 0. 0. 3. 2.\n",
            " 3. 2. 3. 3. 2. 2. 0. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 3. 2. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 3. 0. 0. 3. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 1. 3. 1. 1. 1. 2. 0. 0. 1. 0. 3. 2. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 2. 0. 3. 2. 2. 1. 1. 0. 1. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 1. 2. 2. 2. 0. 3. 3. 3. 3. 1. 1. 0. 0. 0. 3. 1. 0. 3. 3. 1. 2. 3.\n",
            " 3. 0. 2. 1. 0. 1. 3. 0. 1. 3. 0. 3. 0. 2. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 1. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 2. 1. 3. 3. 3. 1. 3. 0. 2. 1. 2. 1. 3. 0. 3. 2. 0. 2. 1.\n",
            " 1. 0. 3. 2. 2. 0. 3. 3. 1. 3. 0. 2. 3. 0. 2. 0. 2. 2. 0. 3. 1. 1. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 2. 2. 2. 1. 3. 0. 2. 3. 1. 0. 3. 3. 0. 2. 1. 1.\n",
            " 1. 0. 0. 1. 1. 2. 1. 2. 2. 0. 1. 0. 2. 3. 3. 2. 0. 2. 0. 2. 3. 2. 0. 0.\n",
            " 0. 3. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 2. 1. 3.\n",
            " 0. 1. 3. 2. 2. 1. 1. 1. 2. 2. 0. 1. 1. 0. 2. 2. 2. 3. 3. 1. 1. 2. 0. 1.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 0. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 3. 2. 1. 2. 3. 1. 2. 1. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 2. 2. 0. 1.\n",
            " 0. 3. 1. 1. 1. 3. 0. 0. 2. 0. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 2. 1. 1. 2. 1. 0. 1. 0. 1. 2. 1. 1. 3. 1. 3. 2. 2. 2. 2. 1. 2.\n",
            " 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 3. 3. 0. 3. 1. 2. 3. 2. 1. 2. 0. 1. 2. 2.\n",
            " 1. 2. 3. 0. 1. 1. 0. 0. 2. 1. 1. 0. 0. 3. 2. 1. 2. 0. 3. 2. 3. 2. 3. 0.\n",
            " 2. 1. 2. 2. 0. 0. 3. 1. 1. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 2. 0. 3. 3. 3. 3. 1. 0. 3. 0. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 3. 2. 3. 1. 3. 2. 2. 2. 1. 2. 1. 3. 1. 1. 2. 0. 1. 1. 1. 3. 2. 2. 2. 1.]\n",
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 2.0, 3.0, 0.0, 3.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0]\n",
            "855     1\n",
            "635     1\n",
            "396     3\n",
            "1816    3\n",
            "1213    1\n",
            "       ..\n",
            "1041    3\n",
            "1799    2\n",
            "1330    2\n",
            "242     3\n",
            "850     3\n",
            "Name: price_range, Length: 600, dtype: int64\n",
            "Accuracy: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prf4.info"
      ],
      "metadata": {
        "id": "CKxUdRVjuIlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94882a4-67bd-4c2a-912c-58b8261136b0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'accuracy': 0.615, 'cluster_idx': 4},\n",
              " 1: {'accuracy': 0.5900000000000001, 'cluster_idx': 1},\n",
              " 2: {'accuracy': 0.5894999999999999, 'cluster_idx': 2},\n",
              " 3: {'accuracy': 0.624, 'cluster_idx': 2},\n",
              " 4: {'accuracy': 0.611, 'cluster_idx': 2},\n",
              " 5: {'accuracy': 0.6075, 'cluster_idx': 1},\n",
              " 6: {'accuracy': 0.554, 'cluster_idx': 2},\n",
              " 7: {'accuracy': 0.5900000000000001, 'cluster_idx': 4},\n",
              " 8: {'accuracy': 0.5984999999999999, 'cluster_idx': 1},\n",
              " 9: {'accuracy': 0.6305, 'cluster_idx': 4},\n",
              " 10: {'accuracy': 0.587, 'cluster_idx': 5},\n",
              " 11: {'accuracy': 0.575, 'cluster_idx': 1},\n",
              " 12: {'accuracy': 0.6449999999999999, 'cluster_idx': 2},\n",
              " 13: {'accuracy': 0.6035, 'cluster_idx': 2},\n",
              " 14: {'accuracy': 0.524, 'cluster_idx': 4},\n",
              " 15: {'accuracy': 0.5745, 'cluster_idx': 2},\n",
              " 16: {'accuracy': 0.6185, 'cluster_idx': 0},\n",
              " 17: {'accuracy': 0.617, 'cluster_idx': 1},\n",
              " 18: {'accuracy': 0.5545, 'cluster_idx': 1},\n",
              " 19: {'accuracy': 0.585, 'cluster_idx': 1},\n",
              " 20: {'accuracy': 0.6385000000000001, 'cluster_idx': 1},\n",
              " 21: {'accuracy': 0.608, 'cluster_idx': 0},\n",
              " 22: {'accuracy': 0.595, 'cluster_idx': 2},\n",
              " 23: {'accuracy': 0.6020000000000001, 'cluster_idx': 0},\n",
              " 24: {'accuracy': 0.576, 'cluster_idx': 2},\n",
              " 25: {'accuracy': 0.5955, 'cluster_idx': 2},\n",
              " 26: {'accuracy': 0.5685, 'cluster_idx': 0},\n",
              " 27: {'accuracy': 0.5525, 'cluster_idx': 4},\n",
              " 28: {'accuracy': 0.6965, 'cluster_idx': 5},\n",
              " 29: {'accuracy': 0.7040000000000001, 'cluster_idx': 0},\n",
              " 30: {'accuracy': 0.6995, 'cluster_idx': 0},\n",
              " 31: {'accuracy': 0.5459999999999999, 'cluster_idx': 1},\n",
              " 32: {'accuracy': 0.579, 'cluster_idx': 1},\n",
              " 33: {'accuracy': 0.712, 'cluster_idx': 5},\n",
              " 34: {'accuracy': 0.579, 'cluster_idx': 2},\n",
              " 35: {'accuracy': 0.5675, 'cluster_idx': 0},\n",
              " 36: {'accuracy': 0.6345, 'cluster_idx': 1},\n",
              " 37: {'accuracy': 0.7310000000000001, 'cluster_idx': 5},\n",
              " 38: {'accuracy': 0.625, 'cluster_idx': 1},\n",
              " 39: {'accuracy': 0.6370000000000001, 'cluster_idx': 1},\n",
              " 40: {'accuracy': 0.6235, 'cluster_idx': 2},\n",
              " 41: {'accuracy': 0.7224999999999999, 'cluster_idx': 0},\n",
              " 42: {'accuracy': 0.7285, 'cluster_idx': 5},\n",
              " 43: {'accuracy': 0.575, 'cluster_idx': 4},\n",
              " 44: {'accuracy': 0.676, 'cluster_idx': 1},\n",
              " 45: {'accuracy': 0.6585000000000001, 'cluster_idx': 4},\n",
              " 46: {'accuracy': 0.4765, 'cluster_idx': 2},\n",
              " 47: {'accuracy': 0.7225, 'cluster_idx': 0},\n",
              " 48: {'accuracy': 0.6485, 'cluster_idx': 1},\n",
              " 49: {'accuracy': 0.5369999999999999, 'cluster_idx': 3},\n",
              " 50: {'accuracy': 0.641, 'cluster_idx': 0},\n",
              " 51: {'accuracy': 0.688, 'cluster_idx': 0},\n",
              " 52: {'accuracy': 0.5810000000000002, 'cluster_idx': 2},\n",
              " 53: {'accuracy': 0.6795, 'cluster_idx': 5},\n",
              " 54: {'accuracy': 0.6845, 'cluster_idx': 1},\n",
              " 55: {'accuracy': 0.5815, 'cluster_idx': 5},\n",
              " 56: {'accuracy': 0.5965, 'cluster_idx': 1},\n",
              " 57: {'accuracy': 0.711, 'cluster_idx': 0},\n",
              " 58: {'accuracy': 0.659, 'cluster_idx': 4},\n",
              " 59: {'accuracy': 0.5810000000000001, 'cluster_idx': 2},\n",
              " 60: {'accuracy': 0.726, 'cluster_idx': 0},\n",
              " 61: {'accuracy': 0.657, 'cluster_idx': 4},\n",
              " 62: {'accuracy': 0.6535, 'cluster_idx': 0},\n",
              " 63: {'accuracy': 0.7285, 'cluster_idx': 0},\n",
              " 64: {'accuracy': 0.6695, 'cluster_idx': 4},\n",
              " 65: {'accuracy': 0.5285, 'cluster_idx': 2},\n",
              " 66: {'accuracy': 0.5335, 'cluster_idx': 4},\n",
              " 67: {'accuracy': 0.5740000000000001, 'cluster_idx': 2},\n",
              " 68: {'accuracy': 0.616, 'cluster_idx': 4},\n",
              " 69: {'accuracy': 0.5365, 'cluster_idx': 2},\n",
              " 70: {'accuracy': 0.591, 'cluster_idx': 1},\n",
              " 71: {'accuracy': 0.636, 'cluster_idx': 0},\n",
              " 72: {'accuracy': 0.562, 'cluster_idx': 1},\n",
              " 73: {'accuracy': 0.721, 'cluster_idx': 1},\n",
              " 74: {'accuracy': 0.608, 'cluster_idx': 2},\n",
              " 75: {'accuracy': 0.5925, 'cluster_idx': 0},\n",
              " 76: {'accuracy': 0.6245, 'cluster_idx': 2},\n",
              " 77: {'accuracy': 0.6945, 'cluster_idx': 4},\n",
              " 78: {'accuracy': 0.693, 'cluster_idx': 0},\n",
              " 79: {'accuracy': 0.6045, 'cluster_idx': 4},\n",
              " 80: {'accuracy': 0.6449999999999999, 'cluster_idx': 4},\n",
              " 81: {'accuracy': 0.582, 'cluster_idx': 1},\n",
              " 82: {'accuracy': 0.6295, 'cluster_idx': 5},\n",
              " 83: {'accuracy': 0.589, 'cluster_idx': 0},\n",
              " 84: {'accuracy': 0.6819999999999999, 'cluster_idx': 4},\n",
              " 85: {'accuracy': 0.7289999999999999, 'cluster_idx': 0},\n",
              " 86: {'accuracy': 0.5815, 'cluster_idx': 4},\n",
              " 87: {'accuracy': 0.548, 'cluster_idx': 1},\n",
              " 88: {'accuracy': 0.5955, 'cluster_idx': 0},\n",
              " 89: {'accuracy': 0.6289999999999999, 'cluster_idx': 4},\n",
              " 90: {'accuracy': 0.656, 'cluster_idx': 4},\n",
              " 91: {'accuracy': 0.7505, 'cluster_idx': 0},\n",
              " 92: {'accuracy': 0.708, 'cluster_idx': 5},\n",
              " 93: {'accuracy': 0.6605000000000001, 'cluster_idx': 0},\n",
              " 94: {'accuracy': 0.6785, 'cluster_idx': 1},\n",
              " 95: {'accuracy': 0.5469999999999999, 'cluster_idx': 1},\n",
              " 96: {'accuracy': 0.5945, 'cluster_idx': 3},\n",
              " 97: {'accuracy': 0.6020000000000001, 'cluster_idx': 1},\n",
              " 98: {'accuracy': 0.6545, 'cluster_idx': 5},\n",
              " 99: {'accuracy': 0.5890000000000001, 'cluster_idx': 2}}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#spectral\n",
        "getMaxAccuracyCluster(prf4.info)"
      ],
      "metadata": {
        "id": "DR6fU8l7jzxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d309fa9d-bf21-4a64-a31c-2d4c07e0e1e8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4': [77], '1': [73], '2': [12], '5': [37], '0': [91], '3': [96]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'4': 77}\n",
            "{'1': 73}\n",
            "{'2': 12}\n",
            "{'5': 37}\n",
            "{'0': 91}\n",
            "{'3': 96}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': [91], '1': [73], '2': [12], '3': [96], '4': [77], '5': [37]}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treeList = getTreeList(X, getMaxAccuracyCluster(prf4.info))\n",
        "\n",
        "y_preed = predict(X_test, treeList, prf4)\n",
        "\n",
        "print(\"final answer = \", y_preed)\n",
        "print(y_test)\n",
        "  \n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_preed))"
      ],
      "metadata": {
        "id": "aYLQ3qAf-n7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2711067-eb93-4a82-9f93-3f3cb6e4dc8e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'4': [77], '1': [73], '2': [12], '5': [37], '0': [91], '3': [96]}\n",
            "Selecting first maximum accuracy of a decision tree in each cluster:\n",
            "{'4': 77}\n",
            "{'1': 73}\n",
            "{'2': 12}\n",
            "{'5': 37}\n",
            "{'0': 91}\n",
            "{'3': 96}\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 1. 2. 0. 1. 3. 0. 1. 0. 2. 0. 1. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 2. 2. 1. 0. 0. 1. 0. 0. 1. 1. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 0. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 2. 2. 3. 1. 0. 3. 0. 0. 1. 1. 0. 0. 1. 1. 0.\n",
            " 0. 2. 2. 1. 1. 2. 1. 2. 0. 3. 1. 1. 1. 3. 0. 0. 1. 0. 3. 3. 3. 1. 3. 3.\n",
            " 2. 0. 0. 0. 3. 0. 3. 2. 2. 1. 1. 0. 0. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 2. 0. 0. 2. 2. 2. 0. 3. 2. 3. 3. 1. 3. 0. 1. 1. 1. 1. 0. 2. 3. 0. 1. 2.\n",
            " 3. 0. 2. 1. 0. 1. 3. 0. 2. 3. 1. 3. 0. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 1. 1. 3. 3. 3. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 2. 1. 3. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 2. 2. 2. 2. 0. 1. 2. 0. 2. 3. 1. 0. 3. 3. 0. 1. 1. 2.\n",
            " 1. 0. 0. 1. 2. 1. 1. 2. 2. 0. 1. 1. 2. 2. 3. 2. 0. 3. 0. 2. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 3. 1. 1. 2. 1. 0. 1. 2. 0. 0. 2. 0. 0. 2. 1. 2.\n",
            " 0. 2. 2. 2. 2. 1. 1. 2. 3. 2. 0. 1. 0. 0. 0. 3. 2. 1. 2. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 2.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 2. 3. 0. 0. 0. 0. 1. 0. 2. 1. 0. 2. 2. 0. 1.\n",
            " 1. 3. 2. 1. 1. 3. 0. 0. 2. 0. 1. 3. 1. 1. 3. 3. 0. 0. 0. 1. 3. 1. 1. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 1. 1. 1. 0. 2. 1. 1. 3. 1. 3. 3. 2. 2. 2. 1. 2.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 0. 2. 3. 2. 0. 3. 2. 2. 2. 2. 1. 2. 0. 1. 2. 2.\n",
            " 1. 1. 3. 1. 0. 1. 0. 0. 2. 1. 1. 1. 0. 3. 1. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 2. 1. 2. 2. 0. 1. 3. 1. 1. 3. 3. 3. 1. 0. 0. 1. 2. 3. 0. 0. 1. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 1. 2. 0. 0. 3. 0. 2. 2. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 1. 2. 0. 1. 1. 0. 3. 3. 2. 3. 3.\n",
            " 2. 2. 3. 1. 3. 2. 2. 2. 2. 3. 3. 1. 1. 1. 2. 0. 1. 1. 2. 3. 2. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 0. 1. 0. 2. 0. 0. 3. 0.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 1. 3. 2. 0. 0. 1. 1. 0. 0. 1. 0. 3. 2.\n",
            " 3. 3. 2. 2. 1. 2. 0. 1. 2. 2. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 0. 1.\n",
            " 2. 0. 0. 1. 0. 0. 1. 1. 0. 2. 2. 3. 2. 0. 3. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 0. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 1. 2. 3. 0. 3. 2. 1. 1. 1. 0. 0. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 0. 2. 2. 2. 0. 3. 2. 3. 1. 1. 3. 0. 0. 1. 3. 2. 0. 2. 2. 0. 2. 3.\n",
            " 3. 0. 0. 1. 0. 1. 3. 0. 2. 3. 0. 2. 0. 1. 2. 0. 2. 0. 0. 0. 1. 3. 0. 1.\n",
            " 2. 3. 3. 3. 2. 1. 2. 2. 0. 2. 0. 1. 2. 1. 3. 3. 3. 3. 1. 1. 1. 0. 0. 0.\n",
            " 2. 0. 0. 3. 2. 2. 1. 3. 2. 2. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 1. 1. 2. 0.\n",
            " 1. 0. 3. 3. 1. 0. 3. 3. 1. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 3. 1. 0. 0. 2. 3. 2. 2. 2. 3. 3. 2. 2. 0. 2. 3. 1. 0. 3. 2. 0. 0. 1. 1.\n",
            " 1. 0. 0. 1. 2. 2. 2. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 3. 3. 2. 0. 1.\n",
            " 0. 2. 1. 3. 1. 3. 3. 1. 1. 1. 2. 2. 1. 0. 1. 0. 0. 0. 2. 1. 0. 2. 1. 2.\n",
            " 0. 3. 3. 2. 2. 1. 0. 2. 3. 3. 0. 1. 1. 0. 2. 2. 2. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 3. 0. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 2. 3. 0. 2. 2. 0. 2. 2. 0. 1.\n",
            " 1. 3. 1. 1. 1. 3. 0. 1. 2. 1. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 2. 0. 1. 2.\n",
            " 3. 1. 3. 1. 2. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 3. 1. 3. 3. 3. 2. 2. 1. 2.\n",
            " 1. 0. 0. 1. 0. 1. 0. 1. 0. 3. 2. 2. 0. 3. 2. 2. 2. 2. 1. 2. 0. 2. 3. 2.\n",
            " 0. 1. 2. 2. 0. 1. 0. 1. 2. 1. 1. 1. 0. 3. 2. 2. 1. 0. 3. 1. 3. 2. 2. 0.\n",
            " 2. 1. 2. 2. 0. 0. 3. 0. 1. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 0. 0. 1. 3. 0. 2. 1. 1. 3. 3. 0. 3. 0. 2. 3.\n",
            " 0. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 2. 0. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 3. 2. 2. 3. 1. 3. 3. 2. 1. 1. 2. 1. 1. 2. 1. 3. 2. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 0. 1. 3. 1. 1. 0. 3. 0. 1. 0. 1.\n",
            " 3. 2. 1. 0. 1. 3. 1. 1. 0. 1. 0. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 3. 2.\n",
            " 3. 3. 3. 2. 1. 2. 0. 2. 2. 1. 3. 2. 0. 0. 3. 2. 0. 1. 3. 1. 2. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 2. 1. 2. 1. 0. 3. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 1. 1. 1. 3. 1. 2. 0. 1. 0. 2. 1. 2. 0. 0. 2. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 2. 2. 1. 1. 0. 0. 0. 3. 3. 1. 3. 2. 3. 0. 2. 2. 0.\n",
            " 1. 0. 1. 2. 2. 0. 0. 3. 3. 3. 1. 1. 3. 0. 1. 1. 3. 1. 0. 2. 3. 0. 2. 3.\n",
            " 3. 1. 2. 1. 0. 0. 3. 2. 2. 3. 1. 3. 0. 1. 1. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 0. 2. 2. 0. 2. 0. 3. 3. 0. 3. 3. 3. 3. 1. 1. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 2. 1. 3. 2. 3. 2. 3. 0. 3. 1. 3. 1. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 2. 3. 3. 0. 3. 0. 2. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 2. 3. 2. 2. 2. 3. 2. 3. 0. 2. 3. 1. 0. 1. 3. 0. 1. 1. 1.\n",
            " 1. 0. 0. 2. 1. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 2. 1. 0.\n",
            " 2. 2. 1. 1. 1. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 1. 0. 2. 0. 0. 2. 1. 1.\n",
            " 0. 1. 3. 2. 2. 1. 0. 2. 2. 2. 0. 1. 1. 0. 2. 2. 2. 3. 3. 1. 1. 2. 1. 2.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 0. 2. 0. 2. 0. 2. 1. 1. 3. 2. 3. 1. 2. 1. 3.\n",
            " 3. 3. 2. 1. 1. 2. 1. 1. 2. 0. 3. 0. 0. 0. 1. 2. 0. 1. 2. 0. 2. 1. 0. 0.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 2. 1. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 2. 2.\n",
            " 3. 3. 3. 1. 1. 1. 1. 1. 0. 1. 1. 1. 2. 1. 1. 3. 1. 3. 3. 2. 2. 2. 1. 2.\n",
            " 1. 0. 2. 1. 1. 1. 0. 1. 0. 2. 3. 1. 0. 3. 1. 2. 2. 2. 1. 2. 2. 1. 2. 2.\n",
            " 3. 1. 3. 2. 2. 1. 0. 0. 2. 1. 1. 1. 0. 3. 2. 2. 2. 1. 3. 2. 3. 2. 2. 0.\n",
            " 1. 1. 2. 3. 0. 0. 3. 1. 2. 3. 0. 3. 2. 0. 0. 2. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 3. 1. 1. 3. 2. 1. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 0. 1. 1. 1. 3. 3. 1. 3. 2.\n",
            " 2. 2. 3. 1. 3. 2. 1. 2. 0. 2. 2. 3. 1. 1. 2. 0. 1. 2. 1. 2. 2. 2. 3. 0.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 1. 2. 1. 2. 2. 0. 1. 3. 0. 1. 0. 2. 0. 0. 2. 1.\n",
            " 3. 2. 3. 0. 2. 3. 2. 1. 0. 1. 1. 0. 2. 2. 1. 0. 1. 1. 0. 0. 1. 1. 3. 2.\n",
            " 3. 3. 2. 2. 1. 2. 1. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 2. 3. 1. 0. 3. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 0. 0. 1. 0. 3. 2. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 2. 0. 3. 2. 2. 1. 1. 0. 0. 0. 2. 1. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 0. 2. 2. 1. 0. 3. 2. 3. 3. 1. 2. 0. 1. 1. 3. 1. 0. 2. 3. 0. 3. 3.\n",
            " 3. 0. 2. 1. 0. 0. 3. 0. 2. 1. 0. 3. 0. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 1. 2. 2. 0. 2. 0. 1. 1. 0. 3. 3. 3. 2. 1. 2. 2. 0. 1. 0.\n",
            " 1. 1. 1. 3. 2. 1. 1. 3. 3. 2. 1. 3. 0. 2. 1. 3. 1. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 0. 3. 3. 0. 1. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 2. 2. 2. 2. 2. 2. 3. 2. 3. 1. 2. 3. 1. 0. 3. 3. 0. 1. 1. 1.\n",
            " 2. 0. 0. 0. 1. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 1. 3. 1. 3. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 2. 3. 3. 1. 1. 1. 1. 2. 1. 0. 1. 0. 0. 0. 2. 0. 0. 3. 1. 3.\n",
            " 0. 1. 3. 2. 2. 1. 0. 2. 2. 2. 0. 0. 1. 0. 2. 2. 2. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 2. 0. 3. 0. 0. 0. 3. 0. 2. 3. 2. 0. 2. 0. 2. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 1. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 2. 0. 2. 2. 0. 2. 1. 0. 1.\n",
            " 1. 3. 1. 1. 1. 3. 0. 0. 2. 1. 1. 3. 1. 1. 3. 2. 1. 0. 0. 1. 3. 0. 0. 2.\n",
            " 3. 1. 3. 1. 1. 1. 2. 1. 0. 1. 1. 1. 2. 1. 1. 3. 1. 3. 3. 2. 2. 2. 1. 2.\n",
            " 1. 0. 1. 1. 1. 0. 0. 1. 0. 2. 2. 2. 0. 3. 1. 2. 3. 2. 0. 2. 0. 1. 2. 2.\n",
            " 1. 1. 3. 1. 0. 1. 0. 0. 2. 1. 1. 0. 0. 3. 2. 2. 2. 0. 3. 2. 3. 2. 2. 0.\n",
            " 2. 1. 3. 2. 1. 0. 2. 1. 1. 3. 3. 3. 3. 0. 0. 0. 2. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 1. 2. 0. 2. 1. 2. 3. 3. 0. 3. 1. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 1. 1. 0. 1. 3. 3. 1. 3. 3.\n",
            " 2. 1. 3. 1. 3. 2. 2. 2. 1. 3. 2. 3. 1. 0. 2. 0. 1. 1. 1. 3. 2. 2. 3. 3.]\n",
            "[1. 1. 3. 3. 1. 2. 1. 0. 2. 2. 1. 2. 2. 1. 1. 3. 0. 1. 0. 2. 0. 0. 3. 1.\n",
            " 3. 2. 3. 0. 2. 3. 1. 1. 0. 1. 1. 0. 3. 2. 0. 0. 1. 2. 1. 0. 1. 0. 2. 2.\n",
            " 3. 3. 2. 2. 1. 2. 1. 1. 2. 1. 3. 3. 0. 0. 3. 2. 0. 2. 3. 0. 2. 3. 0. 2.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 3. 2. 1. 1. 3. 0. 0. 1. 1. 0. 0. 1. 1. 2.\n",
            " 0. 3. 1. 1. 1. 1. 1. 2. 0. 3. 1. 1. 1. 2. 1. 0. 1. 0. 3. 3. 3. 2. 3. 3.\n",
            " 2. 0. 0. 2. 3. 0. 3. 2. 2. 1. 1. 0. 0. 0. 2. 2. 1. 3. 2. 3. 0. 2. 3. 0.\n",
            " 1. 0. 0. 2. 2. 2. 0. 2. 2. 3. 3. 1. 3. 0. 1. 1. 3. 1. 0. 2. 3. 1. 2. 3.\n",
            " 2. 0. 2. 1. 0. 1. 3. 0. 2. 3. 0. 3. 0. 1. 2. 1. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 2. 2. 3. 3. 3. 0. 2. 2. 0. 2. 1. 1. 1. 0. 3. 3. 3. 3. 1. 2. 2. 0. 0. 0.\n",
            " 2. 0. 1. 3. 2. 1. 1. 3. 2. 3. 1. 3. 0. 3. 1. 3. 1. 3. 0. 3. 2. 1. 2. 1.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 1. 2. 3. 0. 2. 0. 2. 2. 0. 3. 1. 0. 1. 0.\n",
            " 2. 1. 0. 0. 3. 3. 2. 2. 2. 2. 3. 1. 3. 0. 2. 3. 0. 0. 3. 3. 0. 1. 1. 2.\n",
            " 2. 0. 0. 1. 1. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 3. 3. 2. 0. 0.\n",
            " 0. 2. 1. 1. 1. 3. 3. 1. 1. 1. 1. 3. 1. 0. 1. 0. 0. 0. 2. 0. 0. 2. 1. 2.\n",
            " 0. 2. 3. 2. 2. 2. 0. 2. 2. 2. 0. 1. 1. 0. 2. 2. 2. 3. 3. 1. 2. 2. 1. 1.\n",
            " 3. 1. 3. 1. 3. 0. 0. 0. 3. 0. 2. 3. 2. 1. 2. 1. 1. 3. 1. 3. 1. 2. 1. 3.\n",
            " 1. 3. 2. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 2. 0. 2. 3. 0. 2. 2. 0. 1.\n",
            " 1. 3. 0. 1. 1. 1. 0. 0. 2. 1. 1. 3. 2. 1. 2. 2. 1. 0. 0. 1. 3. 0. 1. 2.\n",
            " 3. 1. 3. 2. 1. 1. 2. 1. 0. 1. 1. 1. 1. 1. 1. 3. 1. 3. 3. 2. 2. 2. 1. 1.\n",
            " 2. 0. 1. 2. 1. 1. 1. 1. 0. 2. 3. 2. 0. 3. 1. 2. 2. 2. 1. 2. 0. 1. 3. 3.\n",
            " 1. 1. 3. 2. 0. 1. 0. 0. 2. 1. 1. 0. 0. 3. 2. 2. 2. 0. 2. 2. 3. 2. 2. 0.\n",
            " 2. 1. 2. 2. 0. 0. 3. 1. 1. 3. 3. 3. 3. 0. 0. 1. 0. 3. 0. 0. 2. 1. 3. 1.\n",
            " 3. 1. 3. 2. 3. 1. 3. 1. 3. 1. 0. 0. 3. 0. 3. 1. 2. 3. 3. 0. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 0. 3. 1. 0. 3. 3. 3. 3. 1. 0. 3. 0. 1. 1. 1. 3. 3. 1. 3. 3.\n",
            " 3. 2. 3. 1. 3. 2. 2. 2. 1. 3. 2. 3. 1. 1. 2. 0. 1. 2. 1. 3. 3. 2. 3. 3.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 3. 3. 1. 2. 1. 1. 2. 2. 1. 3. 3. 0. 1. 3. 0. 3. 0. 2. 1. 0. 3. 0.\n",
            " 3. 1. 3. 0. 2. 3. 1. 3. 0. 1. 1. 0. 0. 1. 1. 0. 3. 1. 0. 0. 1. 0. 3. 3.\n",
            " 3. 3. 3. 0. 1. 2. 0. 1. 2. 1. 1. 1. 0. 0. 1. 2. 2. 2. 3. 0. 1. 3. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 2. 2. 3. 1. 0. 3. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 0. 2. 1. 1. 1. 1. 1. 1. 0. 3. 1. 1. 1. 2. 3. 0. 1. 0. 2. 3. 3. 3. 3. 3.\n",
            " 3. 0. 1. 2. 3. 0. 3. 3. 2. 1. 1. 0. 2. 0. 2. 3. 1. 3. 2. 3. 0. 2. 0. 0.\n",
            " 1. 2. 0. 2. 2. 2. 0. 3. 2. 3. 3. 0. 3. 2. 1. 0. 3. 1. 1. 1. 3. 2. 2. 3.\n",
            " 3. 0. 2. 1. 0. 1. 3. 1. 2. 3. 0. 3. 3. 1. 2. 0. 2. 0. 0. 0. 2. 3. 0. 1.\n",
            " 0. 2. 3. 3. 3. 1. 3. 2. 0. 2. 0. 1. 1. 3. 3. 3. 3. 3. 2. 1. 2. 0. 3. 0.\n",
            " 2. 0. 1. 0. 2. 1. 1. 3. 3. 3. 2. 2. 0. 3. 1. 2. 1. 3. 0. 3. 2. 1. 2. 3.\n",
            " 1. 0. 3. 3. 2. 0. 3. 3. 0. 3. 1. 3. 3. 0. 1. 0. 2. 2. 2. 3. 1. 0. 2. 0.\n",
            " 3. 1. 0. 0. 3. 2. 2. 2. 2. 2. 2. 2. 3. 0. 2. 3. 2. 0. 2. 3. 0. 0. 1. 1.\n",
            " 2. 2. 0. 1. 2. 2. 1. 2. 3. 1. 1. 1. 2. 3. 3. 2. 0. 3. 0. 2. 3. 3. 0. 0.\n",
            " 2. 2. 1. 1. 0. 3. 2. 2. 1. 1. 1. 2. 1. 0. 1. 0. 0. 1. 2. 0. 0. 0. 1. 2.\n",
            " 1. 1. 3. 2. 2. 1. 0. 2. 2. 0. 0. 1. 1. 0. 2. 2. 2. 3. 3. 1. 2. 2. 2. 1.\n",
            " 3. 1. 2. 1. 3. 0. 0. 0. 3. 1. 2. 3. 2. 2. 3. 1. 1. 3. 1. 3. 1. 3. 1. 2.\n",
            " 0. 3. 2. 2. 1. 2. 2. 1. 2. 1. 3. 0. 0. 0. 1. 3. 0. 2. 2. 0. 2. 2. 0. 2.\n",
            " 0. 1. 1. 2. 1. 3. 0. 0. 2. 1. 0. 2. 1. 1. 2. 2. 1. 0. 0. 2. 3. 0. 2. 2.\n",
            " 3. 1. 0. 1. 1. 1. 2. 3. 0. 1. 3. 1. 1. 1. 1. 3. 1. 3. 0. 2. 2. 2. 1. 2.\n",
            " 1. 1. 1. 1. 2. 1. 0. 1. 0. 2. 3. 2. 0. 2. 1. 2. 3. 2. 3. 2. 0. 1. 2. 3.\n",
            " 1. 1. 2. 2. 0. 1. 1. 0. 2. 1. 3. 3. 0. 3. 2. 0. 2. 0. 3. 2. 3. 3. 2. 0.\n",
            " 2. 1. 2. 2. 0. 0. 3. 1. 1. 3. 2. 3. 3. 0. 0. 2. 2. 3. 1. 0. 2. 1. 2. 1.\n",
            " 3. 1. 2. 2. 3. 2. 3. 1. 3. 1. 0. 0. 3. 0. 3. 1. 1. 3. 3. 1. 3. 0. 2. 3.\n",
            " 1. 3. 2. 0. 1. 3. 1. 0. 3. 3. 3. 2. 1. 0. 1. 0. 0. 1. 1. 3. 3. 1. 3. 3.\n",
            " 2. 2. 3. 1. 0. 2. 2. 2. 1. 3. 2. 3. 0. 1. 2. 2. 1. 1. 1. 2. 2. 2. 2. 3.]\n",
            "<class 'list'>\n",
            "final answer =  [1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 0.0, 3.0, 2.0, 0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 3.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 2.0, 3.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 3.0, 1.0, 0.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 3.0]\n",
            "855     1\n",
            "635     1\n",
            "396     3\n",
            "1816    3\n",
            "1213    1\n",
            "       ..\n",
            "1041    3\n",
            "1799    2\n",
            "1330    2\n",
            "242     3\n",
            "850     3\n",
            "Name: price_range, Length: 600, dtype: int64\n",
            "Accuracy: 0.9916666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Mrj0TvcTJWKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b61b99a-4d7a-4347-f905-7011ef4b8f9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8285"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "rf = DecisionTreeClassifier()\n",
        "\n",
        "rf.fit(X,y)\n",
        "\n",
        "cross_val_score(rf, X, y, cv = 5).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "VmF1OeRuUfQT"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(ax, prf, cluster_idx):\n",
        "    y = []\n",
        "\n",
        "    for key in prf.info:\n",
        "        if prf.info[key][\"cluster_idx\"] == cluster_idx:\n",
        "            y.append(prf.info[key][\"accuracy\"])\n",
        "    ax.set_title(\"cluster \" + str(cluster_idx))\n",
        "    ax.bar(range(len(y)), y)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ECC8fkUvVsC6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "248efd5b-e858-4179-d9a5-634ee10cef92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x360 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#kmeans\n",
        "f, axes = plt.subplots(1, len(prf.clusters), figsize=(len(prf.clusters) * 5,5))\n",
        "for i in range(len(prf.clusters)):\n",
        "    plot_accuracy(axes[i], prf, i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "K2pXN9K8WD6K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "634bfdf1-97d8-4948-e864-41f5a6c33643"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x360 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#dbscan\n",
        "f, axes = plt.subplots(1, len(prf1.clusters), figsize=(len(prf1.clusters) * 5,5))\n",
        "for i in range(len(prf1.clusters)):\n",
        "    plot_accuracy(axes[i], prf1, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ctNEHJTjewHN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "3df9864b-07ec-45e6-809d-fc895c4e0535"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIIAAAE/CAYAAAA6+WhgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df7RlZ1kn+O9DhaADqGjKbkxSJGqpUyoCXoPd2sgoMIk6iT2gVhwdGIVqeyhFcdCw6BXTcbkadQ0uezozbUlHM3ZLQOx2Si2NtmC7tCVWqQFMYqAs0VQapcQA7S9C4TN/nFPpk8v9cere8/Oez2ets+rsvd+732fvs8976n32u/eu7g4AAAAAe9/j5h0AAAAAALMhEQQAAACwIiSCAAAAAFaERBAAAADAipAIAgAAAFgREkEAAAAAK0IiiMeoqpdU1W/MOw5gtWmLgEWgLQIWhfaISZIIYiqqqqvqMye8zquq6q1V9ddV9QdV9bxJrh/Ye6bUFn1fVb2zqs5X1S2TXDewN026LaqqT62qN1TVf6mqD1bVb1bVsye1fmDvmtL/jd5aVeeq6kNV9faqumGS62fyJIJYOFV1ySaL3pDk95J8SpLXJHlzVe2fWWDAStmiLTqd5LuT/MIMwwFW1CZt0ZOSnEzyhUk+OckdSX6hqp40y9iA1bLF/41ekeSp3f0JSY4k+bdV9dTZRcbFkghaUVV1ZVX9+2Hm9v1V9a82KHPVMGN8yci8X6uqlw7ff2ZV/afhmag/r6o3Duf/+rD426vqL6vq64fzv7qq7qmqD1TVf66qp4+s9z1V9T1V9Y4kf7W+kamqz0ryrCTf291/090/k+SdSV442T0DzNKytUVJ0t13dPcvJvmvE90ZwNwsW1vU3We6+3Xd/d7u/mh3H0tyaZLPnvS+AWZr2dqjJOnud3T3+QuTSR6f5MoJ7RKmYLOMHntYVe1L8vNJ3pLkm5J8NMnaDlb1fUl+Ocn/kMF/PtaSpLufU1Wd5Au6+/SwzmcmuT3J/5TkVJJvTHK8qj67uz88XN+NSb4qyZ+PNCQXfG6SM9092vF6+3A+sISWtC0C9pi90BZV1TOGdZ7eQdzAgljm9qiqfj7J85I8Icldw3WxoIwIWk3XJPm0JK/q7r/q7r/t7p3ceOwjSZ6W5NPGWMeRJD/a3XcPz1zdkeTDSb54pMy/7O4Hu/tvNvj7JyX54Lp5H0zy5B3EDSyGZWyLgL1nqduiqvqEJD+Z5J939/r/KwHLZWnbo+7+6gz6Zl+Z5Je7++92EDczIhG0mq5M8scTONP93UkqyW9X1b1V9c1blH1aku8aDjf8QFV9YBjHp42UeXCLv//LJJ+wbt4nxKUZsMyWsS0C9p6lbYuq6uOT/FySt3X3v9hF7MBiWNr2KEm6+yPDy+dfUFXX7zR4ps+lYavpwSQHquqSbRqZvxr++98l+dDw/d+/sLC7/zTJy5Kkqr40yX+sql+/MMxwgzq/v7u/f4v6eotl9yb59Kp68sjlYV+Q5Ke2+BtgsS1jWwTsPUvZFlXVE5L8bJKzSf7JVmWBpbGU7dEGLknyGRf5N8yQEUGr6beTvDfJa6vqiVX1cVX1JesLdfe5JA8l+caq2jfMJD/6ha6qr62qK4aTD2fQQFwYAvhnST59ZHU/luRbq+rZNfDEqvqqqhrr0q7ufleSe5J87zDef5zk6Ul+5mI2HFgoS9cWDet7fFV9XAa/oZcM4943/mYDC2bp2qKqenySNyf5myQvdgkG7BnL2B59TlVdV1UfP/w/0jcmeU6S/3Rxm84sSQStoO7+aAY3A/vMJH+SwZmkr9+k+MuSvCrJ+zO4MfN/Hln2RUnurqq/THI8ySu6+8xw2S1J7hgOL/y67j41XNe/yqAxOp3kJRcZ+uEMbnT2cJLXJnnRsBEEltASt0U/lkHn68Ykrxm+/6aLXAewIJa0LfqHSb46yQuSfKAGT//5y6r6RxexDmDBLGl7VMN1vi/JuQweJf/13f27F7EOZqy6jYAHAAAAWAVGBAEAAACsCIkgAAAAgBUhEQQAAACwIiSCAAAAAFaERBAAAADAirhkXhVfdtllfdVVV82remBCfud3fufPu3v/vOPYKW0R7A3aImARaIuARbBdWzS3RNBVV12VU6dOzat6YEKq6o/nHcNuaItgb9AWAYtglm1RVV2b5EeS7Evy+u5+7brlB5LckeSThmVu6u4TW61TWwR7w3ZtkUvDAAAAlkhV7UtyW5LrkhxKcmNVHVpX7J8leVN3PzPJ4ST/92yjBBaVRBAAAMByuSbJ6e4+092PJLkzyQ3rynSSTxi+/8Qk/2WG8QELbG6XhgEAALAjlyd5cGT6bJJnrytzS5JfrqpvS/LEJM+bTWjAojMiCAAAYO+5MclPdPcVSb4yyU9W1cf0/6rqSFWdqqpT586dm3mQwOxJBAEAACyXh5JcOTJ9xXDeqG9J8qYk6e7fSvJxSS5bv6LuPtbda929tn//0j7wDLgIEkEAAADL5WSSg1V1dVVdmsHNoI+vK/MnSb4iSarqv88gEWTIDyARBAAAsEy6+3ySo0nuSnJ/Bk8Hu7eqbq2q64fFvivJy6rq7UnekOQl3d3ziRhYJG4WDQAAsGS6+0SSE+vm3Tzy/r4kXzLruIDFZ0QQAAAAwIqQCAIAAABYERJBAAAAACtiz94j6KqbfmHssu957VdNMRKAvWmjdlZ7CsCy2qz/4LeNUeP2Mx03LDIjggAAAABWhEQQAAAAwIqQCAIAAABYERJBAAAAACtCIggAAABgRezZp4YBwCLz1DUAVo0nbsFiMCIIAOAiVNW1VfVAVZ2uqps2WP7DVXXP8PWuqvrAPOIEANiIEUEAAGOqqn1Jbkvy/CRnk5ysquPdfd+FMt39nSPlvy3JM2ceKDOz2QgHIxoAWFRGBAFLw1l4YAFck+R0d5/p7keS3Jnkhi3K35jkDTOJDABgDEYEwYoY95rsZDHPYjoLDyyIy5M8ODJ9NsmzNypYVU9LcnWSt2yy/EiSI0ly4MCByUYJACtgnD7OIvZt5k0iCFgWj56FT5KqunAW/r5Nyt+Y5HtnFBvARg4neXN3f3Sjhd19LMmxJFlbW+tZBgbAgBtYs4okgmCC/JBM1cTOwgPswkNJrhyZvmI4byOHk7x86hEBAEtrHn1IiSBgL9ryLPyqX46x/sdGYnK6PCZ+zzmZ5GBVXZ1BAuhwkm9YX6iqPifJU5L81mzDAwA248T9gEQQsCwmdhbe5RjATnX3+ao6muSuJPuS3N7d91bVrUlOdffxYdHDSe7sbm0MwIpb1eTDqm73MpAIApaFs/AwIbMYpbSXR55194kkJ9bNu3nd9C2zjAkWyWadv73UDsCikXThYkgEjVj2pyrBXuYsPAAAwO5JBAFLw1l4AACA3ZEIAgAAAJiAZbhMTyIIYA/ypCoAAGAjjxunUFVdW1UPVNXpqrppkzJfV1X3VdW9VfVTkw0TAAAAgN3aNhFUVfuS3JbkuiSHktxYVYfWlTmY5NVJvqS7PzfJd0whVgAAALL9yfqq+uGqumf4eldVfWAecQKLZ5xLw65Jcrq7zyRJVd2Z5IYk942UeVmS27r74STp7vdNOlAAAAAec7L++UnOJjlZVce7+9E+Wnd/50j5b0vyzJkHChdhGe6ts1eMkwi6PMmDI9Nnkzx7XZnPSpKq+s0MHut8S3f/0kQijMe6A/BY7oEEwIob52T9qBuTfO+MYgMW3KRuFn1JkoNJnpvkiiS/XlWf392PGX5YVUeSHEmSAwcOTKhqgL1DggMAGMM4J+uTJFX1tCRXJ3nLDOIClsA4iaCHklw5Mn3FcN6os0nu7u6PJPmjqnpXBomhk6OFuvtYkmNJsra21jsNGoDJk4QCgD3pcJI3d/dHN1roZD2snnESQSeTHKyqqzNIAB1O8g3ryvxsBsMNf7yqLsvgUrEzkwwUAABYblvd8sHJh4syzsn6Cw4neflmK3KyHlbPtomg7j5fVUeT3JXB/X9u7+57q+rWJKe6+/hw2Quq6r4kH03yqu5+/zQDB1gG6//D6z+5AMAEjHOyPlX1OUmekuS3ZhsesMjGukdQd59IcmLdvJtH3neSVw5fLBB3XgcAgL1lzJP1ySBBdOewvwaQZHI3i4aZ8AS5AfsBNuY+R7C4Nvvt8h2FndnuZP1w+pZZxgQsB4kgAPY8CSIAWA2uiJgO+3VvkQhiboxqAQBWmVFSAMzD4+YdAAAAAACzIREEAAAAsCJcGrZEXJe5N/lcAQAAmBWJIIA5cPPi5eWzAwBgmUkEAcAESBABALAMJIL4GJ7mBawKyRtWkSdVASw2t45g2iSCAHZJMgEAAPaevZqUkwgCYCYkzGDxGS0EAHufRBAT4XIyYKckiIC9THINgEUjEQSwBJYpWbJMsbI4HDcAALMhEQQAcBGq6tokP5JkX5LXd/drNyjzdUluSdJJ3t7d3zDTIJmYZR3Rs6xxAzB9EkFzsldvOgV7mRELLBvH7ORV1b4ktyV5fpKzSU5W1fHuvm+kzMEkr07yJd39cFV96nyinT3Jh9myvy+O/QUwIBEEm5CsWzzOwrMKJG8W3jVJTnf3mSSpqjuT3JDkvpEyL0tyW3c/nCTd/b5ZBqizCwBsRSIIWArOwq8mSREW0OVJHhyZPpvk2evKfFaSVNVvZpC4vqW7f2k24QHA9pz0Xm0SQcCyWPiz8OwdElDs0iVJDiZ5bpIrkvx6VX1+d39gtFBVHUlyJEkOHDgw6xgBgBUlEbRLHpsOM+MsPCyYFU2YPZTkypHpK4bzRp1Ncnd3fyTJH1XVuzJIDJ0cLdTdx5IcS5K1tbWeWsQAACMkgoC9xFn4KVjRzj5s5mSSg1V1dQYJoMNJ1t+L7GeT3Jjkx6vqsgyS1GdmGiXAHuDyJZgOiSBgWTgLD8xdd5+vqqNJ7spg5OHt3X1vVd2a5FR3Hx8ue0FV3Zfko0le1d3vn1/UAJMnSQPLSyIIWBbOwm/AaB1mwXH2WN19IsmJdfNuHnnfSV45fO0pnkgGAMtPIghYCs7Cw94gqcQikuACYJVIBAFLY5XPwgNcIGkBAOyGRBAAAHM3zQSX5Nlq2OqeNT5rgP/mcfMOAAAAAIDZMCIIAAB4DKOoFl9VXZvkRzK4d+Lru/u1G5T5uiS3JOkkb+/u9Q/aAFaQRBAAAMASqap9SW5L8vwkZ5OcrKrj3X3fSJmDSV6d5Eu6++Gq+tT5RAssGokgVsJW14yPcpYLAGBxGan0qGuSnO7uM0lSVXcmuSHJfSNlXpbktu5+OEm6+30zjxJYSBJBAACwYiRUlt7lSR4cmT6b5NnrynxWklTVb2Zw+dgt3f1L61dUVUeSHEmSAwcOTCVYYLGMdbPoqrq2qh6oqtNVddMGy19SVeeq6p7h66WTDxUAAIAxXZLkYJLnJrkxyY9V1SetL9Tdx7p7rbvX9u/fP+MQgXnYdkTQONefDr2xu49OIUYAANiU0S17h89ybA8luXJk+orhvFFnk9zd3R9J8kdV9a4MEkMnZxMisKjGuTRsnOtPAQCAFSBZsxBOJjlYVVdnkAA6nGT9E8F+NoORQD9eVZdlcKnYmZlGCSykcRJB41x/miQvrKrnJHlXku/s7gc3KAMA7MBGHa9Jd7pmUQcAu9fd56vqaJK7Mrj/z+3dfW9V3ZrkVHcfHy57QVXdl+SjSV7V3e+fX9TAopjUzaJ/LskbuvvDVfVPktyR5MvXF3IjMgAAGI+RN2ylu08kObFu3s0j7zvJK4cvgEeNc7Poba8/7e73d/eHh5OvT/KFG63IjcgAAAAA5mecRNCj159W1aUZXH96fLRAVT11ZPL6JPdPLkQAAAAAJmHbS8PGvP7026vq+iTnk/xFkpdMMWYAAAAAdmCsewSNcf3pq5O8erKhAQAAADBJk7pZNAAwJ572BQDAuCSCAABYeJ6gBQCTMc7NogEAAADYAySCAAAAAFaERBAAAADAipAIAgAAAFgREkEAAAAAK0IiCAAAAGBFSAQBAAAArAiJIAAAAIAVIREEAHARquraqnqgqk5X1U0bLH9JVZ2rqnuGr5fOI04AgI1IBAFLQ+cLmLeq2pfktiTXJTmU5MaqOrRB0Td29zOGr9fPNEgAgC1cMu8AAMYx0vl6fpKzSU5W1fHuvm9d0Td299GZBwisimuSnO7uM0lSVXcmuSHJ+rYIAGAhGREELItHO1/d/UiSC50vgFm6PMmDI9Nnh/PWe2FVvaOq3lxVV260oqo6UlWnqurUuXPnphErAMDHkAgClsXEOl8AU/ZzSa7q7qcn+ZUkd2xUqLuPdfdad6/t379/pgECAKtLIgjYS8bqfDkLD+zCQ0lGk8xXDOc9qrvf390fHk6+PskXzig2AIBtSQQBy2JinS9n4YFdOJnkYFVdXVWXJjmc5Phogap66sjk9Unun2F8AABbcrNoYFk82vnKIAF0OMk3jBaoqqd293uHkzpfwMR19/mqOprkriT7ktze3fdW1a1JTnX38STfXlXXJzmf5C+SvGRuAQMArCMRBCwFnS9gUXT3iSQn1s27eeT9q5O8etZxAQCMQyIIWBo6XwAAALvjHkEAAABLpqquraoHqup0Vd20wfKXVNW5qrpn+HrpPOIEFo8RQQAAAEukqvYluS3J85OcTXKyqo53933rir6xu4/OPEBgoRkRBAAAsFyuSXK6u8909yNJ7kxyw5xjApaERBAAAMByuTzJgyPTZ4fz1nthVb2jqt5cVVfOJjRg0UkEAQAA7D0/l+Sq7n56kl9JcsdGharqSFWdqqpT586dm2mAwHxIBAEAACyXh5KMjvC5YjjvUd39/u7+8HDy9Um+cKMVdfex7l7r7rX9+/dPJVhgsUgEAQAALJeTSQ5W1dVVdWmSw0mOjxaoqqeOTF6f5P4ZxgcsME8NAwAAWCLdfb6qjia5K8m+JLd3971VdWuSU919PMm3V9X1Sc4n+YskL5lbwMBCkQgCAABYMt19IsmJdfNuHnn/6iSvnnVcwOJzaRgAAADAihgrEVRV11bVA1V1uqpu2qLcC6uqq2ptciECAAAAMAnbJoKqal+S25Jcl+RQkhur6tAG5Z6c5BVJ7p50kAAAAADs3jgjgq5Jcrq7z3T3I0nuTHLDBuW+L8kPJPnbCcYHAAAAwISMkwi6PMmDI9Nnh/MeVVXPSnJld//CBGMDAAAAYIJ2fbPoqnpcktcl+a4xyh6pqlNVdercuXO7rRoAAACAizBOIuihJFeOTF8xnHfBk5N8XpJfq6r3JPniJMc3umF0dx/r7rXuXtu/f//OowYAAADgoo2TCDqZ5GBVXV1VlyY5nOT4hYXd/cHuvqy7r+ruq5K8Lcn13X1qKhEDAAAAsCPbJoK6+3ySo0nuSnJ/kjd1971VdWtVXT/tAAEAAACYjEvGKdTdJ5KcWDfv5k3KPnf3YQEAAAAwabu+WTQAAAAAy0EiCAAAAGBFSAQBAAAArAiJIAAAAIAVIREEAAAAsCIkggAAAABWhEQQAMBFqKprq+qBqjpdVTdtUe6FVdVVtTbL+AAAtiIRBAAwpqral+S2JNclOZTkxqo6tEG5Jyd5RZK7ZxshAMDWJIKApeEsPLAArklyurvPdPcjSe5McsMG5b4vyQ8k+dtZBgcAsB2JIGApOAsPLIjLkzw4Mn12OO9RVfWsJFd29y/MMjAAgHFIBAHLwll4YOFV1eOSvC7Jd41R9khVnaqqU+fOnZt+cAAAkQgClsfEzsLrfAG78FCSK0emrxjOu+DJST4vya9V1XuSfHGS4xtdqtrdx7p7rbvX9u/fP8WQAQD+G4kgYE+4mLPwOl/ALpxMcrCqrq6qS5McTnL8wsLu/mB3X9bdV3X3VUneluT67j41n3ABAB5LIghYFhM7Cw+wU919PsnRJHcluT/Jm7r73qq6taqun290AADbkwgCloWz8MBC6O4T3f1Z3f0Z3f39w3k3d/fxDco+VzsETIOnqQI7JREELAVn4QEABjxNFdiNS+YdAMC4uvtEkhPr5t28SdnnziImAIA5ePRpqklSVReepnrfunIXnqb6qtmGBywyI4IAAACWy8SepgqsHokgAACAPeRinqZaVUeq6lRVnTp37tz0gwPmTiIIAABguUzsaardfay717p7bf/+/VMMGVgUEkEAAADLxdNUgR2TCAIAAFginqYK7IanhgEAACwZT1MFdsqIIAAAAIAVIREEAAAAsCIkggAAAABWhEQQAAAAwIqQCAIAAABYERJBAAAAACtCIggAAABgRUgEAQAAAKyIsRJBVXVtVT1QVaer6qYNln9rVb2zqu6pqt+oqkOTDxUAAACA3dg2EVRV+5LcluS6JIeS3LhBouenuvvzu/sZSX4wyesmHikAAAAAuzLOiKBrkpzu7jPd/UiSO5PcMFqguz80MvnEJD25EAEAAACYhEvGKHN5kgdHps8mefb6QlX18iSvTHJpki/faEVVdSTJkSQ5cODAxcYKAAAAwC5M7GbR3X1bd39Gku9J8s82KXOsu9e6e23//v2TqhoAAACAMYyTCHooyZUj01cM523mziRfs5ugAAAAAJi8cRJBJ5McrKqrq+rSJIeTHB8tUFUHRya/Ksm7JxciAAAAAJOw7T2Cuvt8VR1NcleSfUlu7+57q+rWJKe6+3iSo1X1vCQfSfJwkhdPM2gAAAAALt44N4tOd59IcmLdvJtH3r9iwnEBAAAAMGETu1k0AAAAAItNIggAAABgRUgEAQBchKq6tqoeqKrTVXXTBsu/tareWVX3VNVvVNWhecQJALARiSBgaeh8AfNWVfuS3JbkuiSHkty4QVvzU939+d39jCQ/mOR1Mw4TAGBTEkHAUtD5AhbENUlOd/eZ7n4kyZ1Jbhgt0N0fGpl8YpKeYXwAAFuSCAKWhc4XsAguT/LgyPTZ4bzHqKqXV9UfZpCU/vaNVlRVR6rqVFWdOnfu3FSCBQBYTyIIWBY6X8DS6O7buvszknxPkn+2SZlj3b3W3Wv79++fbYAAwMqSCAL2FJ0vYMoeSnLlyPQVw3mbuTPJ10w1IgCAiyARBCwLnS9gEZxMcrCqrq6qS5McTnJ8tEBVHRyZ/Kok755hfMCK8BANYKckgoBlofMFzF13n09yNMldSe5P8qbuvreqbq2q64fFjlbVvVV1T5JXJnnxnMIF9igP0QB245J5BwAwju4+X1UXOl/7ktx+ofOV5FR3H8+g8/W8JB9J8nB0voAp6O4TSU6sm3fzyPtXzDwoYNU8+hCNJKmqCw/RuO9CAQ/RADYjEQQsDZ0vAIAkGz9E49nrC1XVyzMYmXhpki+fTWjAonNpGAAAwB40zkM0PE0VVo9EEAAAwHKZ2EM0PE0VVo9EEAAAwHLxEA1gx9wjCAAAYIl4iAawGxJBAAAAS8ZDNICdcmkYAAAAwIqQCAIAAABYERJBAAAAACtCIggAAABgRUgEAQAAAKwIiSAAAACAFSERBAAAALAiJIIAAAAAVoREEAAAAMCKkAgCAAAAWBESQQAAAAArQiIIAAAAYEVIBAEAAACsiLESQVV1bVU9UFWnq+qmDZa/sqruq6p3VNWvVtXTJh8qAAAAALuxbSKoqvYluS3JdUkOJbmxqg6tK/Z7Sda6++lJ3pzkBycdKAAAAAC7M86IoGuSnO7uM939SJI7k9wwWqC739rdfz2cfFuSKyYbJgAAAAC7NU4i6PIkD45Mnx3O28y3JPnF3QQFAAAAwORdMsmVVdU3JllL8mWbLD+S5EiSHDhwYJJVAwAAALCNcUYEPZTkypHpK4bzHqOqnpfkNUmu7+4Pb7Si7j7W3WvdvbZ///6dxAsAAADADo2TCDqZ5GBVXV1VlyY5nOT4aIGqemaSH80gCfS+yYcJAAAAwG5tmwjq7vNJjia5K8n9Sd7U3fdW1a1Vdf2w2A8leVKSn66qe6rq+CarAwBYalV1bVU9UFWnq+qmDZa/sqruq6p3VNWvVtXT5hEnAMBGxrpHUHefSHJi3bybR94/b8JxAXyMqro2yY8k2Zfk9d392nXLX5nkpUnOJzmX5Ju7+49nHiiwZ1XVviS3JXl+Bg/QOFlVx7v7vpFiv5dkrbv/uqr+aZIfTPL1s48WAOBjjXNpGMDcjXS+rktyKMmNVXVoXbELna+nJ3lzBp0vgEm6Jsnp7j7T3Y8kuTPJDaMFuvut3f3Xw8m3ZXB/RQCAhSARBCwLnS9gEVye5MGR6bPDeZv5liS/ONWIAAAugkQQsCx0voClUlXfmGQtg3spbrT8SFWdqqpT586dm21wwNJzvzJgpySCgD1H5wuYooeSXDkyfcVw3mNU1fOSvCaDJ6p+eKMVdfex7l7r7rX9+/dPJVhgb3LJPLAbEkHAstD5AhbBySQHq+rqqro0yeEkj3laalU9M8mPZtAOvW8OMQJ7n0vmgR2TCAKWhc4XMHfdfT7J0SR3Jbk/yZu6+96qurWqrh8W+6EkT0ry01V1T1Ud32R1ADvlknlgx8Z6fDzAvHX3+aq60Pnal+T2C52vJKe6+3ge2/lKkj/p7us3XSnADnT3iSQn1s27eeT982YeFMAmRi6Z/7JNlh9JciRJDhw4MMPIgHmRCAKWhs4XAECSi79k/su2umQ+ybEkWVtb68mHCiwal4YBAAAsF5fMAzsmEQQAALBE3K8M2A2XhgEAACwZl8wDO2VEEAAAAMCKkAgCAAAAWBESQQAAAAArQiIIAAAAYEVIBAEAAACsCIkgAAAAgBUhEQQAAACwIiSCAAAAAFaERBAAAADAipAIAgAAAFgREkEAAAAAK0IiCAAAAGBFSAQBAAAArAiJIAAAAIAVIREEAAAAsCIkggAAAABWhEQQAAAAwIqQCAIAAABYERJBAAAAACtirERQVV1bVQ9U1emqummD5c+pqt+tqvNV9aLJhwkAAADAbm2bCKqqfUluS3JdkkNJbqyqQ+uK/UmSlyT5qUkHCAAAAMBkXDJGmWuSnO7uM0lSVXcmuSHJfRcKdPd7hsv+bgoxAgAAADAB41wadnmSB0emzw7nAQAAALBEZnqz6Ko6UlWnqurUuXPnZlk1sAe4XxmwCLRFAMAyGycR9FCSK0emrxjOu2jdfay717epvc4AAA06SURBVLp7bf/+/TtZBbCi3K8MWATaIgBg2Y2TCDqZ5GBVXV1VlyY5nOT4dMMC+BiP3q+sux9JcuF+ZY/q7vd09zuSuF8ZMC3aImAhGJ0I7NS2iaDuPp/kaJK7ktyf5E3dfW9V3VpV1ydJVX1RVZ1N8rVJfrSq7p1m0MBKcr8yYBFMrC1yyTywU0YnArsxzlPD0t0nkpxYN+/mkfcnM7hkDGDhVdWRJEeS5MCBA3OOBlhV3X0sybEkWVtb6zmHAywXT3YGdmymN4sG2AX3KwMWwcTaIoBdMDoR2DGJIGBZuF8ZsAi0RcCe4gQZrB6JIGApuF8ZsAi0RcCCMDoR2LGx7hEEsAjcrwxYBNoiYAE8OjoxgwTQ4STfMN+QgGVhRBAAAMASMToR2A0jggAAAJaM0YnAThkRBAAAALAiJIIAAAAAVoREEAAAAMCKkAgCAAAAWBESQQAAAAArQiIIAAAAYEVIBAEAAACsCIkgAAAAgBUhEQQAAACwIiSCAAAAAFaERBAAAADAipAIAgAAAFgREkEAAAAAK0IiCAAAAGBFSAQBAAAArAiJIAAAAIAVIREEAAAAsCIkggAAAABWhEQQAAAAwIqQCAIAAABYERJBAAAAACtCIggAAABgRUgEAQAAAKwIiSAAAACAFTFWIqiqrq2qB6rqdFXdtMHyJ1TVG4fL766qqyYdKIC2CFgE2iJgEWiLgJ3aNhFUVfuS3JbkuiSHktxYVYfWFfuWJA9392cm+eEkPzDpQIHVpi0CFoG2CFgE2iJgN8YZEXRNktPdfaa7H0lyZ5Ib1pW5Ickdw/dvTvIVVVWTCxNAWwQsBG0RsAi0RcCOjZMIujzJgyPTZ4fzNizT3eeTfDDJp0wiQIAhbRGwCLRFwCLQFgE7Vt29dYGqFyW5trtfOpz+piTP7u6jI2V+f1jm7HD6D4dl/nzduo4kOTKc/OwkD+wi9suS/Pm2paZLDGJYlPrnGcPTunv/tCtZwLZonp/5vOpexW1W9/LUqy1aPIsam7gu3qLGtohxrWpbdMEq/m6pW92LWPeWbdElY6zgoSRXjkxfMZy3UZmzVXVJkk9M8v71K+ruY0mOjVHntqrqVHevTWJdYhDDste/KDFM2UK1RfPc3/OqexW3Wd2rdZyNSVs0pkWNTVwXb1FjW9S4ZmSh2qILVvF3S93qXsa6x7k07GSSg1V1dVVdmuRwkuPryhxP8uLh+xcleUtvN9QI4OJoi4BFoC0CFoG2CNixbUcEdff5qjqa5K4k+5Lc3t33VtWtSU519/Ek/ybJT1bV6SR/kUFDBDAx2iJgEWiLgEWgLQJ2Y5xLw9LdJ5KcWDfv5pH3f5vkaycb2rYmMnxxl8QwIIb5158sRgxTtWBt0Tz397zqXsVtVvfq1Ds2bdHYFjU2cV28RY1tUeOaiQVriy5Yxd8tdat76ere9mbRAAAAAOwN49wjCAAAAIA9YOETQVV1bVU9UFWnq+qmDZY/oareOFx+d1VdNeH6r6yqt1bVfVV1b1W9YoMyz62qD1bVPcPXzRuta5dxvKeq3jlc/6kNlldV/cvhfnhHVT1rwvV/9sj23VNVH6qq71hXZuL7oapur6r3DR9/eWHeJ1fVr1TVu4f/PmWTv33xsMy7q+rFG5XZYf0/VFV/MNzP/6GqPmmTv93yM9tlDLdU1UMj+/orN/nbLb8/XLx57tNJHVNj1rXj796U6h7rmN9lvRu297PY7i3qnsV2f1xV/XZVvX1Y9z8fzr96+Lt6evg7e+kM6/6Jqvqjke1+xqTr3gsWtY2fZVs1Rixza8t2ENfUv+9jxDW3dnCHcc19n62q7dqfmlIfbbNjYV2ZqfXNtmvfamDifbKacV9sN21n7bIPtkndM+l/7aZt3u1v8iZ1v3Gk3vdU1T2b/O3Fb3d3L+wrgxuf/WGST09yaZK3Jzm0rsz/nuRfD98fTvLGCcfw1CTPGr5/cpJ3bRDDc5P8/JT3xXuSXLbF8q9M8otJKskXJ7l7yp/LnyZ52rT3Q5LnJHlWkt8fmfeDSW4avr8pyQ9s8HefnOTM8N+nDN8/ZUL1vyDJJcP3P7BR/eN8ZruM4ZYk/8cYn9OW3x+vi/4s5rpPJ3VMjVnXjr57U6x722N+AvVu2N7PYru3qHsW211JnjR8//gkdw9/R96U5PBw/r9O8k9nWPdPJHnRNLd72V/zbo+2iW1mbdUYscytLdtBXFP/vo8R19zawR3GNfd9toqvcdqfTKmPttmxsK7MczOlvtl27Vtm0CfLDPpiO207M4E+2CZ1z6T/tdO2eZzvxE7qXrf8/0xy86S2e9FHBF2T5HR3n+nuR5LcmeSGdWVuSHLH8P2bk3xFVdWkAuju93b37w7f/9ck9ye5fFLrn6Abkvy/PfC2JJ9UVU+dUl1fkeQPu/uPp7T+R3X3r2fwlINRo5/5HUm+ZoM//R+T/Ep3/0V3P5zkV5JcO4n6u/uXu/v8cPJtSa642PXuNoYxjfP94eKszD7dxXdvWnVP3Rbt/dS3e56/NcPfjb8cTj5++OokX57B72oyve3erG62tzLt0W7Msy3byrzaue3Msx3cYVzMx9z6aEtwLMyiTzb1vtg8+2Dz7H/Ns9+1Vd3D787XJXnDDmLb0KIngi5P8uDI9Nl87Bf90TLDg+ODST5lGsEMhzQ+M4Mzluv9gxoMbf/FqvrcKVTfSX65qn6nqo5ssHycfTUph7P5QTjt/ZAkf6+73zt8/6dJ/t4GZWa1P745g6z/Rrb7zHbr6HB45O2bDM2c5TGxKua9T6d9TG1nnO/eNG13zE/MuvZ+ptu9wW/N1Le7qvYNhxu/L4P/tP1hkg+M/Kdrasf6+rq7+8J2f/9wu3+4qp4wjbqX3Lzbo63Mu63azrzbsq3MrJ3bzjzbwa3Mo43kYyxEH21OfbNF6JPNqy+2KH2wefS/5t3v+kdJ/qy7373J8ove7kVPBC2MqnpSkp9J8h3d/aF1i383g6F5X5Dk/0rys1MI4Uu7+1lJrkvy8qp6zhTq2FYN7hFxfZKf3mDxLPbDY/RgLNxczh5X1WuSnE/y7zYpMs3P7P9J8hlJnpHkvRkMFWTvW4h2IJnLd29mx/xW7f20t3uDumey3d390e5+RgZn2K5J8jnTqGecuqvq85K8ehjDF2UwvPx7ZhUPE7EwbdV25vn/iA0szG/7PNvBi4xrYfYZszXHvtlc27dF6YvNqx2YU/9rEdqZG7P1aKCL3u5FTwQ9lOTKkekrhvM2LFNVlyT5xCTvn2QQVfX4DBqaf9fd/3798u7+0IWh7d19Isnjq+qyScbQ3Q8N/31fkv+QwX/UR42zrybhuiS/291/tkGMU98PQ392YYjl8N/3bVBmqvujql6S5KuT/C/DhvBjjPGZ7Vh3/9mw8/R3SX5sk3XP6phYJXPdp9M8psY0zndvKsY85ndtk/Z+Jtu9Ud2z2u4LuvsDSd6a5B9kMJz9kuGiqR/rI3VfOxz639394SQ/ntkf68tgYdv4BWirtjO3tmwrs/6+b2ae7eDFxrUo+2wFzbWPNs++2QL0yebZF5trH2xe/a9597uG35//Ockbt4jxord70RNBJ5McrMGTSy7NYBjc8XVljie5cDfyFyV5y2YHxk4Mr8f7N0nu7+7XbVLm71+45rWqrslgv04sGVVVT6yqJ194n8HNsn5/XbHjSf7XGvjiJB8cGbo3SZtmI6e9H0aMfuYvTvL/bVDmriQvqKqnDIfvvWA4b9eq6tok353k+u7+603KjPOZ7SaG0WuN//Em6x7n+8PFmds+nfYxNaZxvntTMeYxv9s6Nmvvp77dm9U9o+3eX8Onb1TVxyd5fgb3XHhrBr+ryfS2e6O6/2DkP5qVwT0IZn2sL4OFbOMXpK3aztzasq3M4vs+Rgxzawd3Etci7LMVNbc+2jz7ZgvSJ5tnX2xufbB59r8WoN/1vCR/0N1nN4lvZ9vdE7ir+DRfGdx5/V0Z3K/gNcN5t2ZwECTJx2UwNO50kt9O8ukTrv9LMxj29o4k9wxfX5nkW5N867DM0ST3ZnB38Lcl+YcTjuHTh+t++7CeC/thNIZKcttwP70zydoUPosnZtCYfOLIvKnuhwwauvcm+UgG11p+SwbXF/9qkncn+Y9JPnlYdi3J60f+9puHx8XpJP/bBOs/ncE1oBeOhwtPRPi0JCe2+swmGMNPDj/nd2TQyDx1fQybfX+8dn1MzmWfTvKYGrO+sb97M6p7w2N+wvVu1t5Pfbu3qHsW2/30JL83rOP3M3wixfCY++1hm/fTSZ4ww7rfMtzu30/ybzN8spjXx+y/hWvjZ91WjRHP3NqyHcQ19e/7GHHNrR3cYVxz32er+tqo/ckM+mhbHAtT75tt1r5lRn2yzLAvdjFtZybcB9uk7pn0vzapeyb9ro3qHs7/iQuf8UjZXW93Df8YAAAAgD1u0S8NAwAAAGBCJIIAAAAAVoREEAAAAMCKkAgCAAAAWBESQQAAAAArQiIIAAAAYEVIBAEAAACsCIkgAAAAgBXx/wPOAdrp4IjZgwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#agglomerative\n",
        "f, axes = plt.subplots(1, len(prf2.clusters), figsize=(len(prf2.clusters) * 5,5))\n",
        "for i in range(len(prf2.clusters)):\n",
        "    plot_accuracy(axes[i], prf2, i)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9lFSKVy3e9si",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "837f8281-65f4-40e5-d14b-669eadb3a140"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x360 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#gaussian\n",
        "f, axes = plt.subplots(1, len(prf3.clusters), figsize=(len(prf3.clusters) * 5,5))\n",
        "for i in range(len(prf3.clusters)):\n",
        "    plot_accuracy(axes[i], prf3, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "T7YZS7C6kJ7X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "2717074c-92d0-4dde-93d7-4a00a63bad39"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x360 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#spectral clusterings\n",
        "f, axes = plt.subplots(1, len(prf4.clusters), figsize=(len(prf4.clusters) * 5,5))\n",
        "for i in range(len(prf4.clusters)):\n",
        "    plot_accuracy(axes[i], prf4, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "or0wJBAFfSgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72242210-8f22-440c-cf78-3d9a7f051801"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4],\n",
              "       [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwbNWXHliN7y",
        "outputId": "9d15b07c-1279-4cd3-ce64-4a250a5b42de"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8UVX4qx7iRCx"
      },
      "execution_count": 58,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "RFpruningMobilePrice.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}